{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LGpbq4tSiOw"
      },
      "source": [
        "# Bài tập tại lớp 2\n",
        "# Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e8vwb3zTACs"
      },
      "source": [
        "### Tóm tắt nội dung\n",
        "Trong bài tập này, các bạn sẽ giải quyết 02 vấn đề trong assignment 1 bằng Neural Network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbebJwTgTC9a"
      },
      "source": [
        "## Mục lục\n",
        "* [1. Hướng Dẫn](#C1)\n",
        "    * [1.1. Cấu trúc file](#C1_1)\n",
        "    * [1.2. Sử dụng gradient_check.py ](#C1_2)\n",
        "* [2. Sử dụng util.py ](#C2)\n",
        "    * [2.1. Hàm load_npy()](#C2_1)\n",
        "    * [2.2. Hàm load_list()](#C2_2)\n",
        "    * [2.3. Hàm save_list()](#C2_3)\n",
        "    * [2.4. Hàm get_vehicle_data()](#C2_4)\n",
        "    * [2.5. Hàm read_mnist_gz()](#C2_5)\n",
        "    * [2.6. Hàm get_mnist_data()](#C2_6)\n",
        "    * [2.7. Hàm plot_loss()](#C2_7)\n",
        "    * [2.8. Hàm normalize()](#C2_8)\n",
        "    * [2.9. Hàm normalize_vehicle()](#C2_9)\n",
        "    * [2.10. Hàm create_one_hot()](#C2_10)\n",
        "    * [2.11. Hàm add_one()](#C2_11)\n",
        "* [3. Hiện thực neural network bằng numpy](#C3)\n",
        "    * [3.1. Class Layer](#C3_1)\n",
        "    * [3.2. Class NeuralNet](#C3_2)\n",
        "    * [3.3. Huấn luyện mô hình](#C3_4)\n",
        "        * [3.3.1 Lựa chọn thông số](#C3_4_1)\n",
        "        * [3.3.2 Vehicle Classification](#C3_4_2)\n",
        "        * [3.3.3 MNIST Classification](#C3_4_3)\n",
        "* [4. Hiện thực neural network bằng tensorflow](#C4)   \n",
        "* [5. Kết quả](#C5)\n",
        "    * [5.1. Vehicle Classification](#C5_1)\n",
        "    * [5.2. MNIST Classification](#C5_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f8tLypk1elE"
      },
      "source": [
        "## 1. Hướng dẫn <a id='C1'></a>\n",
        "Chương này sẽ hướng dẫn những điều cần thiết để hoàn thành bài tập này."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kESB1ROATIF7"
      },
      "source": [
        "Để có thể hoàn tất bài tập này, các bạn cần nắm rõ những kiến thức sau: \n",
        "- Neural Networks - Fully connected networks là gì, nguyên tắc hoạt động\n",
        "ra sao.\n",
        "- Giải thuật Feedforward và BackPropagation trong bài toán NN.\n",
        "- Giải thuật gradient descent - Batch and Mini-batch.\n",
        "- Regularization để tránh overfitting trong NN.\n",
        "\n",
        "Bạn có thể tham khảo lại bài giảng của lớp để nắm vững các nội dung này. Ngoài ra, các bạn có thể đặt câu hỏi cho đội ngũ giảng dạy nếu có thắc mắc.\n",
        "\n",
        "Bài tập này sẽ gồm có hai bài chính:\n",
        "- Bài 1: phân loại dữ liệu hai lớp dùng neural networks.\n",
        "- Bài 2: phân loại tập fashion MNIST.\n",
        "\n",
        "Giải quyết hai bài trên bằng **cả numpy và TensorFlow**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLgPOx1DpSwb"
      },
      "source": [
        "### 1.1. Cấu trúc file <a id='C1_1'></a>\n",
        "Bài tập lớn này được đi kèm với các file sau: \n",
        "- util.py: cung cấp các hàm để đọc dữ liệu trong thưc mục data thành các\n",
        "ma trận numpy. Bạn không cần chỉnh sửa file này.\n",
        "- activation_np.py: các hàm activation cơ bản sẽ cần người học thực thi\n",
        "- dnn_np.py: cung cấp các hàm dựng sẵn để giải quyết bài 1 và bài 2,\n",
        "dùng numpy.\n",
        "- dnn_tf.py: sử dụng Tensorflow để giải quyết bài 1 và 2.\n",
        "- vehicles.dat: dữ liệu của bài 1.\n",
        "- /fashion-mnist/*.gz: dữ liệu của bài 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2. Sử dụng gradient_check.py <a id='C1_2'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "File này cung cấp các hàm cho bạn kiếm tra tính toán gradient của bạn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"gradient_check.py\n",
        "This file provides functions for you to check your gradient computation\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pdb\n",
        "\n",
        "\n",
        "def rel_error(x, y):\n",
        "    \"\"\"\n",
        "    function to determine relative error between expected output results from our actual implementation of a layer\n",
        "    :param x: expected output, arbitrary shape\n",
        "    :param y: output from our implementation\n",
        "    :return:  relative error > 1e-2 means that the result is probably wrong\n",
        "                             <= e-7, you should be happy\n",
        "    \"\"\"\n",
        "    return np.max(np.abs(x - y)/ np.maximum(1e-8, np.abs(x) + np.abs(y)))\n",
        "\n",
        "\n",
        "def eval_numerical_gradient(layer,x, df, verbose = True, h = 0.00001):\n",
        "    \"\"\"\n",
        "    a naive implementation of numerical gradient of f at x\n",
        "    :param f: should be a function that takes a single argument x\n",
        "    :param x: is the point to evaluate the gradient at\n",
        "    :param verbose:\n",
        "    :param h:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    fw = layer.forward(x)\n",
        "    grad = np.zeros_like(layer.w)\n",
        "    it = np.nditer(layer.w, flags = ['multi_index'], op_flags = ['readwrite'])\n",
        "    while not it.finished:\n",
        "\n",
        "        ix = it.multi_index\n",
        "        oldval = layer.w[ix].copy()\n",
        "        layer.w[ix] = oldval + h\n",
        "        fxph  = layer.forward(x) #evaluate f(x+h)\n",
        "        layer.w[ix] = oldval - h\n",
        "        fxmh  = layer.forward(x)\n",
        "        layer.w[ix] = oldval.copy()\n",
        "\n",
        "        grad[ix] = np.sum((fxph - fxmh)*df)/ (2*h)\n",
        "        if verbose:\n",
        "            print(ix, grad[ix])\n",
        "        it.iternext()\n",
        "    return grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caPRYRLnVwu8"
      },
      "source": [
        "## 2. Sử dụng util.py <a id='C2'></a>\n",
        "\n",
        "Chương này mô tả các feature trong file util.py."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzajf88D1elI"
      },
      "source": [
        "Sử dụng các thư viện sau:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1gHJ1OZONpud"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This files helps you read data from data files\n",
        "\"\"\"\n",
        "import pickle\n",
        "import gzip\n",
        "import glob\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28JBrurd1elL"
      },
      "source": [
        "### 2.1. Hàm load_npy() <a id='C2_1'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVIKDhzh1elM"
      },
      "source": [
        "Mục đích: Sử dụng để load numpy data file\n",
        "- Input: file_name\n",
        "- Output: obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1JV27SB0l0fD"
      },
      "outputs": [],
      "source": [
        "def load_npy(file_name):\n",
        "    \"\"\"load_npy\n",
        "    Load numpy data file. This is needed as python 2.7 pickle uses ascii as default encoding method but python 3.x uses utf-8.abs\n",
        "\n",
        "    :param file_name: npy file path\n",
        "    \n",
        "    :return obj: loaded numpy object\n",
        "    \"\"\"\n",
        "    \n",
        "    if (sys.version_info[0] >= 3):\n",
        "        obj = np.load(file_name, encoding='latin1')\n",
        "    elif (sys.version_info[0] >=2):\n",
        "        obj = np.load(file_name)\n",
        "    \n",
        "    return obj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BesGbm3E1elN"
      },
      "source": [
        "### 2.2. Hàm load_list() <a id='C2_2'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXq9HYyV1elO"
      },
      "source": [
        "Mục đích: Sử dụng để load 1 list object vào file_name\n",
        "- Input: file_name\n",
        "- Output: list_obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eB6CKQKm1elO"
      },
      "outputs": [],
      "source": [
        "def load_list(file_name):\n",
        "    \"\"\"load_list\n",
        "    Load a list object to file_name.\n",
        "\n",
        "    :param file_name: string, file name.\n",
        "    \"\"\"\n",
        "    end_of_file = False\n",
        "    list_obj = [] \n",
        "    f = open(file_name, 'rb')\n",
        "    python_version = sys.version_info[0]\n",
        "    while (not end_of_file):\n",
        "        try:\n",
        "            if (python_version >= 3):\n",
        "                list_obj.append(pickle.load(f, encoding='latin1'))\n",
        "            elif (python_version >=2):\n",
        "                list_obj.append(pickle.load(f))\n",
        "        except EOFError:\n",
        "            end_of_file = True\n",
        "            print(\"EOF Reached\")\n",
        "\n",
        "    f.close()\n",
        "    return list_obj "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtUXzgXa1elP"
      },
      "source": [
        "### 2.3. Hàm save_list() <a id='C2_3'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgPGQJNA1elP"
      },
      "source": [
        "Mục đích: Sử dụng để save 1 list object vào trong file_name\n",
        "- Input: list_obj, file_name\n",
        "- Output: Save data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5J7H6UCb1elP"
      },
      "outputs": [],
      "source": [
        "def save_list(list_obj, file_name):\n",
        "    \"\"\"save_list\n",
        "    Save a list object to file_name\n",
        "    \n",
        "    :param list_obj: List of objects to be saved.\n",
        "    :param file_name: file name.\n",
        "    \"\"\"\n",
        "\n",
        "    f = open(file_name, 'wb')\n",
        "    for obj in list_obj:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "    f.close() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oviD4R61elQ"
      },
      "source": [
        "### 2.4. Hàm get_vehicle_data() <a id='C2_4'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsrEaD6I1elQ"
      },
      "source": [
        "Mục đích: Sử dụng để load vehicle data trong thư mục\n",
        "- Input: Lấy data trong thư mục\n",
        "- Output: List của data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "frvdaf0y1elQ"
      },
      "outputs": [],
      "source": [
        "def get_vehicle_data():\n",
        "    \"\"\"\n",
        "    Load vehicle data and return it as a list: [train_x, train_y, test_x, test_y]\n",
        "    \"\"\"\n",
        "    print('Reading vehicle data...')\n",
        "    train_x, train_y, test_x, test_y = load_list('./data/vehicles.dat')\n",
        "    train_x = np.transpose(train_x, (2,0,1))\n",
        "    test_x = np.transpose(test_x, (2,0,1)) \n",
        "\n",
        "    print('Done reading')\n",
        "    return train_x, train_y, test_x, test_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "numqxZoz1elR"
      },
      "source": [
        "### 2.5. Hàm read_mnist_gz() <a id='C2_5'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNLA1gUG1elR"
      },
      "source": [
        "Mục đích: Dùng để đọc fashion MNIST data dưới dạng nén\n",
        "- Input: data_path, offset\n",
        "- Output: dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qphe51lS1elR"
      },
      "outputs": [],
      "source": [
        "def read_mnist_gz(data_path, offset):\n",
        "    with gzip.open(data_path, 'rb') as f:\n",
        "        dataset = np.frombuffer(f.read(), dtype=np.uint8, offset=offset)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tt50Vtc1elS"
      },
      "source": [
        "### 2.6. Hàm get_mnist_data() <a id='C2_6'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmCuNsbw1elS"
      },
      "source": [
        "Mục đích: Dùng để load fashion MNIST data\n",
        "- Input: sampling_step\n",
        "- Output: List của data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "r08oC5sO1elS",
        "outputId": "07b2d610-fd47-4eb8-cf6b-484ee0ce0f50"
      },
      "outputs": [],
      "source": [
        "def get_mnist_data(sampling_step=20):\n",
        "    print('Reading fashion MNIST data...')\n",
        "    train_x = read_mnist_gz('./data/fashion-mnist/train-images-idx3-ubyte.gz', 16)\n",
        "    train_y = read_mnist_gz('./data/fashion-mnist/train-labels-idx1-ubyte.gz', 8)\n",
        "    test_x = read_mnist_gz('./data/fashion-mnist/t10k-images-idx3-ubyte.gz', 16)\n",
        "    test_y = read_mnist_gz('./data/fashion-mnist/t10k-labels-idx1-ubyte.gz', 8)\n",
        "    num_train = len(train_y)\n",
        "    num_test = len(test_y)\n",
        "\n",
        "    train_x = train_x.reshape((num_train, 28*28))\n",
        "    test_x = test_x.reshape((num_test, 28*28))\n",
        "\n",
        "    val_x = train_x[50000:,:]\n",
        "    val_y = train_y[50000:]\n",
        "    train_x = train_x[:50000,:]\n",
        "    train_y = train_y[:50000]\n",
        "\n",
        "    train_x = train_x[0::sampling_step,:]\n",
        "    train_y = train_y[0::sampling_step]\n",
        "    val_x = val_x[0::sampling_step,:]\n",
        "    val_y = val_y[0::sampling_step]\n",
        "    test_x = test_x[0::sampling_step,:]\n",
        "    test_y = test_y[0::sampling_step]\n",
        " \n",
        "    print(\"Done reading\")\n",
        "    return train_x.astype(np.float32), train_y, val_x.astype(np.float32), val_y, test_x.astype(np.float32), test_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.7. Hàm plot_loss() <a id='C2_7'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mục đích: Hiện thực đồ thị"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_loss(loss, fig=1, color='b'):\n",
        "    plt.figure(fig)\n",
        "    plt.clf()\n",
        "    plt.plot(loss, color='b')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.8. Hàm normalize() <a id='C2_8'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mục đích: Chuẩn hóa\n",
        "- Input: train_x, val_x, test_x\n",
        "- Output: train_x, val_x, test_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize(train_x, val_x, test_x):\n",
        "    \"\"\"normalize\n",
        "    This function computes train mean and standard deviation on all pixels then applying data scaling on train_x, val_x and test_x using these computed values\n",
        "\n",
        "    :param train_x: train samples, shape=(num_train, num_feature)\n",
        "    :param val_x: validation samples, shape=(num_val, num_feature)\n",
        "    :param test_x: test samples, shape=(num_test, num_feature)\n",
        "    \"\"\"\n",
        "    # train_mean and train_std should have the shape of (1, 1)\n",
        "    train_mean = np.mean(train_x, axis=(0,1), dtype=np.float64, keepdims=True)\n",
        "    train_std = np.std(train_x, axis=(0,1), dtype=np.float64, keepdims=True)\n",
        "\n",
        "    train_x = (train_x-train_mean)/train_std\n",
        "    val_x = (val_x-train_mean)/train_std\n",
        "    test_x = (test_x-train_mean)/train_std\n",
        "    return train_x, val_x, test_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.9. Hàm normalize_vehicle() <a id='C2_9'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mục đích: Chuẩn hóa dữ liệu vehicles\n",
        "- Input: train_x, test_x\n",
        "- Output: train_x, test_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_vehicle(train_x, test_x):\n",
        "    # train_mean and train_std should have the shape of (1, 1)\n",
        "    train_mean = np.mean(train_x, axis=0, dtype=np.float64, keepdims=True)\n",
        "    train_std = np.std(train_x, axis=0, dtype=np.float64, keepdims=True)\n",
        "\n",
        "    train_x = (train_x-train_mean)/train_std\n",
        "    test_x = (test_x-train_mean)/train_std\n",
        "\n",
        "    return train_x, test_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.10. Hàm create_one_hot() <a id='C2_10'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mục đích: Tạo ma trận one-hot \n",
        "- Input: labels, num_k\n",
        "- Output: eye_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_one_hot(labels, num_k=10):\n",
        "    \"\"\"create_one_hot\n",
        "    This function creates a one-hot (one-of-k) matrix based on the given labels\n",
        "\n",
        "    :param labels: list of labels, each label is one of 0, 1, 2,... , num_k - 1\n",
        "    :param num_k: number of classes we want to classify\n",
        "    \"\"\"\n",
        "    eye_mat = np.eye(num_k)\n",
        "    return eye_mat[labels, :].astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.11. Hàm add_one() <a id='C2_11'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Input: x\n",
        "- Output: x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading fashion MNIST data...\n",
            "Done reading\n"
          ]
        }
      ],
      "source": [
        "def add_one(x):\n",
        "    \"\"\"add_one\n",
        "    \n",
        "    This function add ones as an additional feature for x\n",
        "    :param x: input data\n",
        "    \"\"\"\n",
        "    x = np.concatenate((x, np.ones((x.shape[0], 1))), axis=1)\n",
        "    return x\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    get_mnist_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yzZpItjWqe4"
      },
      "source": [
        "## 3. Hiện thực neural network bằng numpy <a id='C3'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecv42PtbW2YX"
      },
      "source": [
        "### 3.1. Class Layer <a id='C3_1'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Layer(object):\n",
        "    def __init__(self, w_shape, activation, reg = 1e-5):\n",
        "        \"\"\"__init__\n",
        "\n",
        "        :param w_shape: create w with shape w_shape using normal distribution\n",
        "        :param activation: string, indicating which activation function to be used\n",
        "        \"\"\"\n",
        "        \n",
        "        mean = 0\n",
        "        std = 1\n",
        "        self.w = np.random.normal(0, np.sqrt(2./np.sum(w_shape)), w_shape)\n",
        "        self.activation = activation\n",
        "        self.reg = reg\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"forward\n",
        "        This function compute the output of this layer\n",
        "        \n",
        "        :param x: input\n",
        "        \"\"\"\n",
        "        # [TODO 1.2]\n",
        "        result = np.dot(x, self.w)\n",
        "        \n",
        "        # Compute different types of activation\n",
        "        if (self.activation == 'sigmoid'):\n",
        "            result = sigmoid(result)\n",
        "        elif (self.activation == 'relu'):\n",
        "            result = reLU(result)\n",
        "        elif (self.activation == 'tanh'):\n",
        "            result = tanh(result)\n",
        "        elif (self.activation == 'softmax'):\n",
        "            result = softmax_minus_max(result)\n",
        "\n",
        "        self.output = result\n",
        "        return result\n",
        "\n",
        "    def backward(self, x, delta_dot_w_prev):\n",
        "        \"\"\"backward\n",
        "        This function compute the gradient of the loss function with respect to the parameter (w) of this layer\n",
        "\n",
        "        :param x: input of the layer\n",
        "        :param delta_dot_w_prev: delta^(l+1) dot product with w^(l+1)T, computed from the next layer (in feedforward direction) or previous layer (in backpropagation direction)\n",
        "        \"\"\"\n",
        "        # [TODO 1.2]\n",
        "        # Compute delta_last factor from the output\n",
        "        if(self.activation == 'sigmoid'):\n",
        "            g = self.output.copy() \n",
        "            delta = delta_dot_w_prev*sigmoid_grad(g)\n",
        "            w_grad = (x.T).dot(delta)\n",
        "        \n",
        "        elif(self.activation == 'tanh'):\n",
        "            g = self.output.copy() \n",
        "            delta = delta_dot_w_prev*tanh_grad(g)\n",
        "            w_grad = (x.T).dot(delta)\n",
        "\n",
        "        elif(self.activation == 'relu'):\n",
        "            #backprop ReLU nonlinearity here\n",
        "            g = self.output\n",
        "            delta = delta_dot_w_prev.copy()\n",
        "            delta[g <= 0] = 0\n",
        "            w_grad =  np.dot( x.T, delta)\n",
        "\n",
        "        # [TODO 1.4] Implement L2 regularization on weights here\n",
        "        w_grad +=  self.reg*self.w\n",
        "        return w_grad, delta.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMUaX4rn1elY"
      },
      "source": [
        "### 3.2. Class NeuralNet <a id='C3_2'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NeuralNet(object):\n",
        "    def __init__(self, num_class=2, reg = 1e-5):\n",
        "        self.layers = []\n",
        "        self.momentum = []\n",
        "        self.reg = reg\n",
        "        self.num_class = num_class\n",
        "        \n",
        "    def add_linear_layer(self, w_shape, activation):\n",
        "        \"\"\"add_linear_layer\n",
        "\n",
        "        :param w_shape: create w with shape w_shape using normal distribution\n",
        "        :param activation: string, indicating which activation function to be used\n",
        "        \"\"\"\n",
        "        if(len(self.layers) != 0):\n",
        "            if(w_shape[0] != self.layers[-1].w.shape[-1]):\n",
        "                raise ValueError(\"Shape does not match between the added layer and previous hidden layer.\")\n",
        "\n",
        "        if(activation == 'sigmoid'):\n",
        "            self.layers.append(Layer(w_shape, 'sigmoid', self.reg))\n",
        "        elif(activation == 'relu'):\n",
        "            self.layers.append(Layer(w_shape, 'relu', self.reg)) \n",
        "        elif(activation == 'tanh'):\n",
        "            self.layers.append(Layer(w_shape, 'tanh', self.reg))\n",
        "        elif(activation == 'softmax'):\n",
        "            self.layers.append(Layer(w_shape, 'softmax', self.reg))\n",
        "        self.momentum.append(np.zeros_like(self.layers[-1].w))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"forward\n",
        "\n",
        "        :param x: input\n",
        "        \"\"\"\n",
        "        all_x = [x]\n",
        "        for layer in self.layers:\n",
        "            all_x.append(layer.forward(all_x[-1]))\n",
        "        \n",
        "        return all_x\n",
        "\n",
        "\n",
        "    def compute_loss(self, y, y_hat):\n",
        "        \"\"\"compute_loss\n",
        "        Compute the average cross entropy loss using y (label) and y_hat (predicted class)\n",
        "\n",
        "        :param y:  the label, the actual class of the samples. e.g. 3-class classification with 9 data samples y = [0 0 0 1 1 1 2 2 2]\n",
        "        :param y_hat: the propabilities that the given samples belong to class 1\n",
        "        \"\"\"\n",
        "\n",
        "        # [TODO 1.3]\n",
        "        # Estimating cross entropy loss from y_hat and y \n",
        "        correct_log_probs = np.log(y_hat)*y\n",
        "        data_loss = -np.sum(correct_log_probs)/y.shape[0]\n",
        "\n",
        "        #estimating regularization loss from all layers\n",
        "        reg_loss = 0.0\n",
        "        for i in range(len(self.layers)):\n",
        "            reg_loss += 0.5*self.reg*np.sum(self.layers[i].w * self.layers[i].w)\n",
        "\n",
        "        data_loss += reg_loss\n",
        "\n",
        "        return data_loss\n",
        "    \n",
        "    def backward(self, y, all_x):\n",
        "        \"\"\"backward\n",
        "\n",
        "        :param y: the label, the actual class of the samples. e.g. 3-class classification with 9 data samples y = [0 0 0 1 1 1 2 2 2]\n",
        "        :param all_x: input data and activation from every layer\n",
        "        \"\"\"\n",
        "        \n",
        "        # [TODO 1.5] Compute delta factor from the output\n",
        "        # delta = all_x[-1].copy()\n",
        "        # delta[:, y.astype(int)] -= 1\n",
        "        # delta /= y.shape[0]\n",
        "        delta = (all_x[-1].copy() - y) / y.shape[0]\n",
        "        \n",
        "        # [TODO 1.5] Compute gradient of the loss function with respect to w of softmax layer, use delta from the output\n",
        "        grad_last = self.layers[-2].output.T.dot(delta) + self.reg*self.layers[-1].w\n",
        "        # grad_last = np.dot(all_x[-2].T, delta) + (self.layers[-1].w * self.reg / y.shape[0])\n",
        "\n",
        "        grad_list = []\n",
        "        grad_list.append(grad_last)\n",
        "        \n",
        "        for i in range(len(self.layers) - 1)[::-1]:\n",
        "            prev_layer = self.layers[i+1]\n",
        "            layer = self.layers[i]\n",
        "            x = all_x[i]\n",
        "\t    # [TODO 1.5] Compute delta_dot_w_prev factor for previous layer (in backpropagation direction)\n",
        "\t    # delta_prev: delta^(l+1), in the start of this loop, delta_prev is also delta^(L) or delta_last\n",
        "\t    # delta_dot_w_prev: delta^(l+1) dot product with w^(l+1)T\n",
        "            delta_dot_w_prev = delta.dot(prev_layer.w.T)\n",
        "\t    # Use delta_dot_w_prev to compute delta factor for the next layer (in backpropagation direction)\n",
        "            grad_w, delta = layer.backward(x, delta_dot_w_prev)\n",
        "            grad_list.append(grad_w.copy())\n",
        "\n",
        "        grad_list = grad_list[::-1]\n",
        "        return grad_list\n",
        "    \n",
        "    def update_weight(self, grad_list, learning_rate):\n",
        "        \"\"\"update_weight\n",
        "        Update w using the computed gradient\n",
        "\n",
        "        :param grad: gradient computed from the loss\n",
        "        :param learning_rate: float, learning rate\n",
        "        \"\"\"\n",
        "        for i in range(len(self.layers)):\n",
        "            layer = self.layers[i]\n",
        "            grad = grad_list[i]\n",
        "            layer.w = layer.w - learning_rate * grad\n",
        "    \n",
        "    \n",
        "    def update_weight_momentum(self, grad_list, learning_rate, momentum_rate):\n",
        "        \"\"\"update_weight_momentum\n",
        "        Update w using SGD with momentum\n",
        "\n",
        "        :param grad: gradient computed from the loss\n",
        "        :param learning_rate: float, learning rate\n",
        "        :param momentum_rate: float, momentum rate\n",
        "        \"\"\"\n",
        "        for i in range(len(self.layers)):\n",
        "            layer = self.layers[i]\n",
        "            self.momentum[i] = self.momentum[i]*momentum_rate + learning_rate*grad_list[i]\n",
        "            layer.w = layer.w - self.momentum[i]\n",
        "\n",
        "    def predict(self, x_test):\n",
        "        y_hat = self.forward(x_test)[-1]\n",
        "        return np.argmax(y_hat, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e3JORB8PEfL"
      },
      "source": [
        "### 3.3. Huấn luyện mô hình <a id='C3_3'></a>\n",
        "\n",
        "Để điều chỉnh quá trình huấn luyện, bạn có thể thay đổi các thuộc tính của\n",
        "biến cfg:\n",
        "\n",
        "- num_epoch: số lượng vòng lặp cho quá trình huấn luyện.\n",
        "- batch_size: số lượng mẫu trong một batch.\n",
        "- learning_rate: hệ số học.\n",
        "- momentum_rate: hệ số động lực γ.\n",
        "- num_train: số lượng mẫu sẽ dùng để train trong train_x.\n",
        "- reg: hệ số λ cho regularization.\n",
        "- visualize: True hoặc False, xác định xem có vẽ đồ thị lúc huấn luyện hay không.\n",
        "- epochs_to_draw: số epoch cần trải qua để vẽ đồ thị."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4.1 Lựa chọn thông số <a id='C3_4_1'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- num_epoch: 500 (cho vehicle classification) và 300 (cho MNIST classification)\n",
        "- batch_size: 100 (cho vehicle classification) và 200 (cho MNIST classification)\n",
        "- learning_rate: 0.01 (cho vehicle classification) và 0.001 (cho MNIST classification)\n",
        "- momentum_rate: 0.9\n",
        "- num_train: train_x.shape\n",
        "- reg: 0.00015\n",
        "- visualize: False (cho vehicle classification), False (cho MNIST classification)\n",
        "- epochs_to_draw: 100 (cho vehicle classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HEoEEijecqXi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from util import *\n",
        "from activation_np import *\n",
        "from gradient_check import *\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pdb\n",
        "\n",
        "\n",
        "class Config(object):\n",
        "    def __init__(self, num_epoch=1000, batch_size=100, learning_rate=0.0005, momentum_rate=0.9, epochs_to_draw=10, reg=0.00015, num_train=1000, visualize=True):\n",
        "        self.num_epoch = num_epoch\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.momentum_rate = momentum_rate\n",
        "        self.epochs_to_draw = epochs_to_draw\n",
        "        self.reg = reg\n",
        "        self.num_train = num_train\n",
        "        self.visualize = visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(y_hat, test_y):\n",
        "    \"\"\"test\n",
        "    Compute the confusion matrix based on labels and predicted values \n",
        "\n",
        "    :param y_hat: predicted probabilites, output of classifier.feed_forward\n",
        "    :param test_y: test labels\n",
        "    \"\"\"\n",
        "    if (y_hat.ndim == 2):\n",
        "        y_hat = np.argmax(y_hat, axis=1)\n",
        "    num_class = np.unique(test_y).size\n",
        "    confusion_mat = np.zeros((num_class, num_class))\n",
        "\n",
        "    for i in range(num_class):\n",
        "        class_i_idx = test_y == i\n",
        "        num_class_i = np.sum(class_i_idx)\n",
        "        y_hat_i = y_hat[class_i_idx]\n",
        "        for j in range(num_class):\n",
        "            confusion_mat[i,j] = 1.0*np.sum(y_hat_i == j)/num_class_i\n",
        "\n",
        "    np.set_printoptions(precision=2)\n",
        "    print('Confusion matrix:')\n",
        "    print(confusion_mat)\n",
        "    print('Diagonal values:')\n",
        "    print(confusion_mat.flatten()[0::(num_class+1)])\n",
        "\n",
        "\n",
        "def unit_test_layer(your_layer):\n",
        "    \"\"\"unit test layer\n",
        "\n",
        "    This function is used to test layer backward and forward for a random datapoint\n",
        "    error < 1e-8 - you should be happy\n",
        "    error > e-3  - probably wrong in your implementation\n",
        "    \"\"\"\n",
        "    # generate a random data point\n",
        "    x_test = np.random.randn(1, your_layer.w.shape[0])\n",
        "    layer_sigmoid = Layer(your_layer.w.shape, your_layer.activation, reg = 0.0)\n",
        "\n",
        "    #randomize the partial derivative of the cost function w.r.t the next layer    \n",
        "    delta_prev = np.ones((1,your_layer.w.shape[1]))\n",
        "    \n",
        "    # evaluate the numerical gradient of the layer\n",
        "    numerical_grad = eval_numerical_gradient(layer_sigmoid, x_test, delta_prev, False)\n",
        "\n",
        "    #evaluate the gradient using back propagation algorithm\n",
        "    layer_sigmoid.forward(x_test)\n",
        "    w_grad, delta = layer_sigmoid.backward(x_test, delta_prev)\n",
        "\n",
        "    #print out the relative error\n",
        "    error = rel_error(w_grad, numerical_grad)\n",
        "    print(\"Relative error between numerical grad and function grad is: %e\" %error)\n",
        "\n",
        "def minibatch_train(net, train_x, train_y, cfg):\n",
        "    \"\"\"minibatch_train\n",
        "    Train your neural network using minibatch strategy\n",
        "\n",
        "    :param net: NeuralNet object\n",
        "    :param train_x: numpy tensor, train data\n",
        "    :param train_y: numpy tensor, train label\n",
        "    :param cfg: Config object\n",
        "    \"\"\"\n",
        "    # [TODO 1.6] Implement mini-batch training\n",
        "    # convert to (N,1) shape to concatenate with train_x data\n",
        "    train_y_reshape = train_y.reshape(train_y.shape[0],1)\n",
        "    \n",
        "    #Mini-batch gradient descent implementation\n",
        "    all_data_set = np.concatenate((train_x, train_y_reshape), axis = 1)\n",
        "    \n",
        "    all_loss = []\n",
        "    for e in range(cfg.num_epoch):\n",
        "        all_data_set_shuffle = np.random.shuffle(all_data_set) \n",
        "        mini_batch_data_set = np.array_split(all_data_set, cfg.batch_size, axis = 0)\n",
        "        total_loss = 0.0\n",
        "        \n",
        "        for idx, batch in enumerate(mini_batch_data_set):\n",
        "            train_batch_y = batch[:, -1].copy()\n",
        "            train_batch_y = create_one_hot(train_batch_y.astype(int), net.num_class)\n",
        "\n",
        "            train_batch_x = batch[:, :-1].copy()\n",
        "             \n",
        "            all_x = net.forward(train_batch_x)\n",
        "            y_hat = all_x[-1]\n",
        "            loss = net.compute_loss(train_batch_y, y_hat)\n",
        "            if np.isnan(loss):\n",
        "                raise ValueError(\"Loss is NaN\")\n",
        "            grads = net.backward(train_batch_y, all_x)\n",
        "            #net.update_weight(grads, cfg.learning_rate)\n",
        "            net.update_weight_momentum(grads, cfg.learning_rate, cfg.momentum_rate)\n",
        "            total_loss += loss\n",
        "\n",
        "        #printing\n",
        "        if (cfg.visualize and e % cfg.epochs_to_draw == cfg.epochs_to_draw-1):\n",
        "            plot_loss(all_loss, 2)\n",
        "            plt.show()\n",
        "            plt.pause(0.01)\n",
        "\n",
        "        print(\"Epoch %d: loss is %.5f\" % (e+1, total_loss/cfg.batch_size))\n",
        "        all_loss.append(total_loss/cfg.batch_size)\n",
        "\n",
        "def batch_train(net, train_x, train_y, cfg):\n",
        "    \"\"\"batch_train\n",
        "    Train the neural network using batch SGD\n",
        "\n",
        "    :param net: NeuralNet object\n",
        "    :param train_x: numpy tensor, train data\n",
        "    :param train_y: numpy tensor, train label\n",
        "    :param cfg: Config object\n",
        "    \"\"\"\n",
        "\n",
        "    train_set_x = train_x[:cfg.num_train].copy()\n",
        "    train_set_y = train_y[:cfg.num_train].copy()\n",
        "    train_set_y = create_one_hot(train_set_y.astype(int), net.num_class)\n",
        "    all_loss = []\n",
        "\n",
        "    for e in range(cfg.num_epoch):\n",
        "        all_x = net.forward(train_set_x)\n",
        "        y_hat = all_x[-1]\n",
        "        loss = net.compute_loss(train_set_y, y_hat)\n",
        "        grads = net.backward(train_set_y, all_x)\n",
        "        net.update_weight(grads, cfg.learning_rate)\n",
        "\n",
        "        all_loss.append(loss)\n",
        "\n",
        "        if (e % cfg.epochs_to_draw == cfg.epochs_to_draw-1):\n",
        "            plot_loss(all_loss, 2)\n",
        "            plt.show()\n",
        "            plt.pause(0.01)\n",
        "\n",
        "        print(\"Epoch %d: loss is %.5f\" % (e+1, loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqz8CAHLQdYY"
      },
      "source": [
        "### 3.4.2 Vehicle Classification <a id='C3_4_2'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vehicle_classification():\n",
        "    # Load data from file\n",
        "    # Make sure that vehicles.dat is in data/\n",
        "    train_x, train_y, test_x, test_y = get_vehicle_data()\n",
        "    train_x, test_x = normalize_vehicle(train_x, test_x)    \n",
        "\n",
        "    test_y  = test_y.flatten()\n",
        "    train_y = train_y.flatten()\n",
        "    num_class = (np.unique(train_y)).shape[0]\n",
        "\n",
        "    train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1]*train_x.shape[2]))\n",
        "    test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1]*test_x.shape[2]))\n",
        "\n",
        "    # Pad 1 as the third feature of train_x and test_x\n",
        "    train_x = add_one(train_x) \n",
        "    test_x = add_one(test_x)\n",
        "\n",
        "    # Define hyper-parameters and train-related parameters\n",
        "    cfg = Config(num_epoch=500, learning_rate=0.01, epochs_to_draw = 100, num_train=train_x.shape[0])\n",
        "\n",
        "    # Create NN classifier\n",
        "    num_hidden_nodes = 100\n",
        "    num_hidden_nodes_2 = 100\n",
        "    num_hidden_nodes_3 = 100\n",
        "    net = NeuralNet(num_class, cfg.reg)\n",
        "    net.add_linear_layer((train_x.shape[1],num_hidden_nodes), 'relu')\n",
        "    net.add_linear_layer((num_hidden_nodes, num_hidden_nodes_2), 'relu')\n",
        "    net.add_linear_layer((num_hidden_nodes_2, num_hidden_nodes_3), 'relu')\n",
        "    net.add_linear_layer((num_hidden_nodes_3, num_class), 'softmax')\n",
        "    \n",
        "    batch_train(net, train_x, train_y, cfg)\n",
        "    \n",
        "    y_hat = net.forward(test_x)[-1]\n",
        "    test(y_hat, test_y)\n",
        "\n",
        "    metrics = confusion_matrix(test_y, net.predict(test_x))\n",
        "    print(\"Accuracy: \")\n",
        "    print(metrics.trace()/test_y.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relative error between numerical grad and function grad is: 1.332183e-09\n",
            "Reading vehicle data...\n",
            "EOF Reached\n",
            "Done reading\n",
            "Epoch 1: loss is 0.85979\n",
            "Epoch 2: loss is 0.77041\n",
            "Epoch 3: loss is 0.70774\n",
            "Epoch 4: loss is 0.66135\n",
            "Epoch 5: loss is 0.62571\n",
            "Epoch 6: loss is 0.59779\n",
            "Epoch 7: loss is 0.57516\n",
            "Epoch 8: loss is 0.55655\n",
            "Epoch 9: loss is 0.54080\n",
            "Epoch 10: loss is 0.52733\n",
            "Epoch 11: loss is 0.51557\n",
            "Epoch 12: loss is 0.50521\n",
            "Epoch 13: loss is 0.49595\n",
            "Epoch 14: loss is 0.48756\n",
            "Epoch 15: loss is 0.47993\n",
            "Epoch 16: loss is 0.47297\n",
            "Epoch 17: loss is 0.46655\n",
            "Epoch 18: loss is 0.46056\n",
            "Epoch 19: loss is 0.45495\n",
            "Epoch 20: loss is 0.44970\n",
            "Epoch 21: loss is 0.44478\n",
            "Epoch 22: loss is 0.44016\n",
            "Epoch 23: loss is 0.43578\n",
            "Epoch 24: loss is 0.43161\n",
            "Epoch 25: loss is 0.42763\n",
            "Epoch 26: loss is 0.42382\n",
            "Epoch 27: loss is 0.42015\n",
            "Epoch 28: loss is 0.41663\n",
            "Epoch 29: loss is 0.41324\n",
            "Epoch 30: loss is 0.40997\n",
            "Epoch 31: loss is 0.40681\n",
            "Epoch 32: loss is 0.40374\n",
            "Epoch 33: loss is 0.40076\n",
            "Epoch 34: loss is 0.39787\n",
            "Epoch 35: loss is 0.39505\n",
            "Epoch 36: loss is 0.39231\n",
            "Epoch 37: loss is 0.38965\n",
            "Epoch 38: loss is 0.38706\n",
            "Epoch 39: loss is 0.38455\n",
            "Epoch 40: loss is 0.38209\n",
            "Epoch 41: loss is 0.37969\n",
            "Epoch 42: loss is 0.37734\n",
            "Epoch 43: loss is 0.37504\n",
            "Epoch 44: loss is 0.37279\n",
            "Epoch 45: loss is 0.37059\n",
            "Epoch 46: loss is 0.36842\n",
            "Epoch 47: loss is 0.36629\n",
            "Epoch 48: loss is 0.36422\n",
            "Epoch 49: loss is 0.36218\n",
            "Epoch 50: loss is 0.36018\n",
            "Epoch 51: loss is 0.35822\n",
            "Epoch 52: loss is 0.35628\n",
            "Epoch 53: loss is 0.35438\n",
            "Epoch 54: loss is 0.35251\n",
            "Epoch 55: loss is 0.35066\n",
            "Epoch 56: loss is 0.34884\n",
            "Epoch 57: loss is 0.34705\n",
            "Epoch 58: loss is 0.34528\n",
            "Epoch 59: loss is 0.34353\n",
            "Epoch 60: loss is 0.34181\n",
            "Epoch 61: loss is 0.34010\n",
            "Epoch 62: loss is 0.33842\n",
            "Epoch 63: loss is 0.33676\n",
            "Epoch 64: loss is 0.33512\n",
            "Epoch 65: loss is 0.33351\n",
            "Epoch 66: loss is 0.33192\n",
            "Epoch 67: loss is 0.33034\n",
            "Epoch 68: loss is 0.32879\n",
            "Epoch 69: loss is 0.32725\n",
            "Epoch 70: loss is 0.32574\n",
            "Epoch 71: loss is 0.32424\n",
            "Epoch 72: loss is 0.32276\n",
            "Epoch 73: loss is 0.32130\n",
            "Epoch 74: loss is 0.31987\n",
            "Epoch 75: loss is 0.31845\n",
            "Epoch 76: loss is 0.31704\n",
            "Epoch 77: loss is 0.31566\n",
            "Epoch 78: loss is 0.31429\n",
            "Epoch 79: loss is 0.31295\n",
            "Epoch 80: loss is 0.31162\n",
            "Epoch 81: loss is 0.31031\n",
            "Epoch 82: loss is 0.30901\n",
            "Epoch 83: loss is 0.30772\n",
            "Epoch 84: loss is 0.30645\n",
            "Epoch 85: loss is 0.30520\n",
            "Epoch 86: loss is 0.30395\n",
            "Epoch 87: loss is 0.30272\n",
            "Epoch 88: loss is 0.30149\n",
            "Epoch 89: loss is 0.30028\n",
            "Epoch 90: loss is 0.29908\n",
            "Epoch 91: loss is 0.29789\n",
            "Epoch 92: loss is 0.29671\n",
            "Epoch 93: loss is 0.29555\n",
            "Epoch 94: loss is 0.29439\n",
            "Epoch 95: loss is 0.29325\n",
            "Epoch 96: loss is 0.29212\n",
            "Epoch 97: loss is 0.29100\n",
            "Epoch 98: loss is 0.28989\n",
            "Epoch 99: loss is 0.28879\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 100: loss is 0.28770\n",
            "Epoch 101: loss is 0.28662\n",
            "Epoch 102: loss is 0.28555\n",
            "Epoch 103: loss is 0.28449\n",
            "Epoch 104: loss is 0.28344\n",
            "Epoch 105: loss is 0.28240\n",
            "Epoch 106: loss is 0.28136\n",
            "Epoch 107: loss is 0.28034\n",
            "Epoch 108: loss is 0.27932\n",
            "Epoch 109: loss is 0.27831\n",
            "Epoch 110: loss is 0.27730\n",
            "Epoch 111: loss is 0.27630\n",
            "Epoch 112: loss is 0.27532\n",
            "Epoch 113: loss is 0.27434\n",
            "Epoch 114: loss is 0.27337\n",
            "Epoch 115: loss is 0.27241\n",
            "Epoch 116: loss is 0.27145\n",
            "Epoch 117: loss is 0.27050\n",
            "Epoch 118: loss is 0.26955\n",
            "Epoch 119: loss is 0.26862\n",
            "Epoch 120: loss is 0.26768\n",
            "Epoch 121: loss is 0.26676\n",
            "Epoch 122: loss is 0.26584\n",
            "Epoch 123: loss is 0.26492\n",
            "Epoch 124: loss is 0.26401\n",
            "Epoch 125: loss is 0.26310\n",
            "Epoch 126: loss is 0.26221\n",
            "Epoch 127: loss is 0.26131\n",
            "Epoch 128: loss is 0.26043\n",
            "Epoch 129: loss is 0.25955\n",
            "Epoch 130: loss is 0.25868\n",
            "Epoch 131: loss is 0.25782\n",
            "Epoch 132: loss is 0.25696\n",
            "Epoch 133: loss is 0.25611\n",
            "Epoch 134: loss is 0.25526\n",
            "Epoch 135: loss is 0.25442\n",
            "Epoch 136: loss is 0.25357\n",
            "Epoch 137: loss is 0.25274\n",
            "Epoch 138: loss is 0.25191\n",
            "Epoch 139: loss is 0.25109\n",
            "Epoch 140: loss is 0.25028\n",
            "Epoch 141: loss is 0.24946\n",
            "Epoch 142: loss is 0.24865\n",
            "Epoch 143: loss is 0.24784\n",
            "Epoch 144: loss is 0.24704\n",
            "Epoch 145: loss is 0.24624\n",
            "Epoch 146: loss is 0.24545\n",
            "Epoch 147: loss is 0.24466\n",
            "Epoch 148: loss is 0.24388\n",
            "Epoch 149: loss is 0.24309\n",
            "Epoch 150: loss is 0.24232\n",
            "Epoch 151: loss is 0.24154\n",
            "Epoch 152: loss is 0.24077\n",
            "Epoch 153: loss is 0.24000\n",
            "Epoch 154: loss is 0.23924\n",
            "Epoch 155: loss is 0.23847\n",
            "Epoch 156: loss is 0.23771\n",
            "Epoch 157: loss is 0.23696\n",
            "Epoch 158: loss is 0.23621\n",
            "Epoch 159: loss is 0.23546\n",
            "Epoch 160: loss is 0.23471\n",
            "Epoch 161: loss is 0.23396\n",
            "Epoch 162: loss is 0.23322\n",
            "Epoch 163: loss is 0.23248\n",
            "Epoch 164: loss is 0.23174\n",
            "Epoch 165: loss is 0.23100\n",
            "Epoch 166: loss is 0.23027\n",
            "Epoch 167: loss is 0.22954\n",
            "Epoch 168: loss is 0.22882\n",
            "Epoch 169: loss is 0.22810\n",
            "Epoch 170: loss is 0.22739\n",
            "Epoch 171: loss is 0.22667\n",
            "Epoch 172: loss is 0.22597\n",
            "Epoch 173: loss is 0.22526\n",
            "Epoch 174: loss is 0.22456\n",
            "Epoch 175: loss is 0.22386\n",
            "Epoch 176: loss is 0.22316\n",
            "Epoch 177: loss is 0.22247\n",
            "Epoch 178: loss is 0.22178\n",
            "Epoch 179: loss is 0.22110\n",
            "Epoch 180: loss is 0.22042\n",
            "Epoch 181: loss is 0.21974\n",
            "Epoch 182: loss is 0.21907\n",
            "Epoch 183: loss is 0.21840\n",
            "Epoch 184: loss is 0.21774\n",
            "Epoch 185: loss is 0.21708\n",
            "Epoch 186: loss is 0.21642\n",
            "Epoch 187: loss is 0.21576\n",
            "Epoch 188: loss is 0.21511\n",
            "Epoch 189: loss is 0.21446\n",
            "Epoch 190: loss is 0.21382\n",
            "Epoch 191: loss is 0.21317\n",
            "Epoch 192: loss is 0.21253\n",
            "Epoch 193: loss is 0.21189\n",
            "Epoch 194: loss is 0.21126\n",
            "Epoch 195: loss is 0.21062\n",
            "Epoch 196: loss is 0.20999\n",
            "Epoch 197: loss is 0.20936\n",
            "Epoch 198: loss is 0.20873\n",
            "Epoch 199: loss is 0.20810\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200: loss is 0.20748\n",
            "Epoch 201: loss is 0.20686\n",
            "Epoch 202: loss is 0.20624\n",
            "Epoch 203: loss is 0.20563\n",
            "Epoch 204: loss is 0.20502\n",
            "Epoch 205: loss is 0.20441\n",
            "Epoch 206: loss is 0.20380\n",
            "Epoch 207: loss is 0.20320\n",
            "Epoch 208: loss is 0.20260\n",
            "Epoch 209: loss is 0.20200\n",
            "Epoch 210: loss is 0.20141\n",
            "Epoch 211: loss is 0.20081\n",
            "Epoch 212: loss is 0.20022\n",
            "Epoch 213: loss is 0.19964\n",
            "Epoch 214: loss is 0.19905\n",
            "Epoch 215: loss is 0.19847\n",
            "Epoch 216: loss is 0.19789\n",
            "Epoch 217: loss is 0.19731\n",
            "Epoch 218: loss is 0.19673\n",
            "Epoch 219: loss is 0.19616\n",
            "Epoch 220: loss is 0.19559\n",
            "Epoch 221: loss is 0.19502\n",
            "Epoch 222: loss is 0.19446\n",
            "Epoch 223: loss is 0.19389\n",
            "Epoch 224: loss is 0.19333\n",
            "Epoch 225: loss is 0.19278\n",
            "Epoch 226: loss is 0.19222\n",
            "Epoch 227: loss is 0.19166\n",
            "Epoch 228: loss is 0.19111\n",
            "Epoch 229: loss is 0.19056\n",
            "Epoch 230: loss is 0.19001\n",
            "Epoch 231: loss is 0.18947\n",
            "Epoch 232: loss is 0.18893\n",
            "Epoch 233: loss is 0.18838\n",
            "Epoch 234: loss is 0.18785\n",
            "Epoch 235: loss is 0.18731\n",
            "Epoch 236: loss is 0.18677\n",
            "Epoch 237: loss is 0.18624\n",
            "Epoch 238: loss is 0.18570\n",
            "Epoch 239: loss is 0.18517\n",
            "Epoch 240: loss is 0.18464\n",
            "Epoch 241: loss is 0.18412\n",
            "Epoch 242: loss is 0.18359\n",
            "Epoch 243: loss is 0.18307\n",
            "Epoch 244: loss is 0.18254\n",
            "Epoch 245: loss is 0.18202\n",
            "Epoch 246: loss is 0.18150\n",
            "Epoch 247: loss is 0.18098\n",
            "Epoch 248: loss is 0.18047\n",
            "Epoch 249: loss is 0.17995\n",
            "Epoch 250: loss is 0.17944\n",
            "Epoch 251: loss is 0.17893\n",
            "Epoch 252: loss is 0.17842\n",
            "Epoch 253: loss is 0.17791\n",
            "Epoch 254: loss is 0.17741\n",
            "Epoch 255: loss is 0.17690\n",
            "Epoch 256: loss is 0.17640\n",
            "Epoch 257: loss is 0.17589\n",
            "Epoch 258: loss is 0.17539\n",
            "Epoch 259: loss is 0.17490\n",
            "Epoch 260: loss is 0.17440\n",
            "Epoch 261: loss is 0.17390\n",
            "Epoch 262: loss is 0.17341\n",
            "Epoch 263: loss is 0.17292\n",
            "Epoch 264: loss is 0.17243\n",
            "Epoch 265: loss is 0.17193\n",
            "Epoch 266: loss is 0.17145\n",
            "Epoch 267: loss is 0.17096\n",
            "Epoch 268: loss is 0.17047\n",
            "Epoch 269: loss is 0.16999\n",
            "Epoch 270: loss is 0.16950\n",
            "Epoch 271: loss is 0.16902\n",
            "Epoch 272: loss is 0.16854\n",
            "Epoch 273: loss is 0.16806\n",
            "Epoch 274: loss is 0.16759\n",
            "Epoch 275: loss is 0.16711\n",
            "Epoch 276: loss is 0.16664\n",
            "Epoch 277: loss is 0.16616\n",
            "Epoch 278: loss is 0.16569\n",
            "Epoch 279: loss is 0.16522\n",
            "Epoch 280: loss is 0.16475\n",
            "Epoch 281: loss is 0.16429\n",
            "Epoch 282: loss is 0.16382\n",
            "Epoch 283: loss is 0.16335\n",
            "Epoch 284: loss is 0.16289\n",
            "Epoch 285: loss is 0.16243\n",
            "Epoch 286: loss is 0.16197\n",
            "Epoch 287: loss is 0.16151\n",
            "Epoch 288: loss is 0.16105\n",
            "Epoch 289: loss is 0.16059\n",
            "Epoch 290: loss is 0.16014\n",
            "Epoch 291: loss is 0.15969\n",
            "Epoch 292: loss is 0.15924\n",
            "Epoch 293: loss is 0.15880\n",
            "Epoch 294: loss is 0.15835\n",
            "Epoch 295: loss is 0.15791\n",
            "Epoch 296: loss is 0.15747\n",
            "Epoch 297: loss is 0.15703\n",
            "Epoch 298: loss is 0.15659\n",
            "Epoch 299: loss is 0.15615\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3TElEQVR4nO3df1yV9f3/8ecBBUQENRRQyV+ZSio6TIaW1SStldlq+1KrdGzZMttaVJ9ilfZjhbXlza1cNpf92ppk6Vy/LKO0VMqCzPxF/gwrAU0FRQOF6/vHOw4cBeUYnPeB87jfbtfturzOdR1e57od4tn7er/fl8txHEcAAACWBNkuAAAABDbCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACr2tguoDGqq6v1zTffqEOHDnK5XLbLAQAAjeA4jg4cOKBu3bopKKjh9o8WEUa++eYbxcfH2y4DAACcgp07d6pHjx4Nvt4iwkiHDh0kmQ8TGRlpuRoAANAYZWVlio+Pd/8db0iLCCM1t2YiIyMJIwAAtDAn62JBB1YAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVAR1GZs2Sbr5ZWrfOdiUAAASugA4j2dnS7NnSli22KwEAIHAFdBhp186sDx+2WwcAAIGMMCLCCAAANhFGRBgBAMAmwogIIwAA2EQYEWEEAACbAjqMhIebNWEEAAB7AjqM0DICAIB9hBERRgAAsIkwIsIIAAA2EUZEGAEAwCbCiAgjAADYRBgRYQQAAJsIIyKMAABgE2FE0qFDdusAACCQEUZEywgAADYRRkQYAQDAJsKICCMAANhEGBFhBAAAmwgjIowAAGATYURSVZV05IjdWgAACFSEke/ROgIAgB0BHUbCwmq3CSMAANgR0GHE5aoNJIQRAADsCOgwItGJFQAA204pjMyePVu9evVSWFiYkpOTtXr16hMeP2vWLPXv31/t2rVTfHy8br31Vn333XenVHBTI4wAAGCX12EkOztbGRkZmj59uvLz85WYmKhx48appKSk3uNffPFF3XXXXZo+fbo2btyop59+WtnZ2frjH//4g4tvCoQRAADs8jqMzJw5U5MnT1Z6eroSEhI0Z84chYeHa968efUev2rVKo0aNUq//OUv1atXL40dO1ZXX331SVtTfIUwAgCAXV6FkcrKSuXl5Sk1NbX2DYKClJqaqtzc3HrPGTlypPLy8tzhY9u2bXrjjTf005/+tMGfU1FRobKyMo+luRBGAACwq403B+/Zs0dVVVWKiYnx2B8TE6NNmzbVe84vf/lL7dmzR+ecc44cx9HRo0d14403nvA2TVZWlu6//35vSjtlhBEAAOxq9tE0y5Yt08MPP6y///3vys/P18KFC/X666/rwQcfbPCczMxMlZaWupedO3c2W32EEQAA7PKqZSQ6OlrBwcEqLi722F9cXKzY2Nh6z7n33nt13XXX6frrr5ckDR48WOXl5brhhht09913Kyjo+DwUGhqq0NBQb0o7ZYQRAADs8qplJCQkRElJScrJyXHvq66uVk5OjlJSUuo959ChQ8cFjuDgYEmS4zje1tvkwsPNmjACAIAdXrWMSFJGRoYmTZqk4cOHa8SIEZo1a5bKy8uVnp4uSZo4caK6d++urKwsSdL48eM1c+ZMDRs2TMnJydqyZYvuvfdejR8/3h1KbKJlBAAAu7wOI2lpadq9e7emTZumoqIiDR06VEuWLHF3ai0sLPRoCbnnnnvkcrl0zz336Ouvv1aXLl00fvx4PfTQQ033KX4AwggAAHa5HH+4V3ISZWVlioqKUmlpqSIjI5v0vf/v/6Q//1m67TbpL39p0rcGACCgNfbvN8+moWUEAACrCCOEEQAArCKMfB9GDh2yWwcAAIGKMELLCAAAVhFGCCMAAFhFGCGMAABgFWGEMAIAgFUBH0ZqpoOnAysAAHYEfBjp0MGsDxywWwcAAIGKMEIYAQDAKsJInTDi/xPjAwDQ+hBGvg8j1dV0YgUAwIaADyPt29duc6sGAADfC/gwEhQkRUSYbcIIAAC+F/BhRKITKwAANhFGRMsIAAA2EUZEywgAADYRRlQbRg4etFsHAACBiDAiWkYAALCJMCLCCAAANhFGRBgBAMAmwogIIwAA2EQYEWEEAACbCCMijAAAYBNhRIQRAABsIoyIGVgBALCJMCJaRgAAsIkwIsIIAAA2EUbEdPAAANhEGBEtIwAA2EQYkWfLiOPYrQUAgEBDGFFtGHEcqbzcbi0AAAQawoik8HAp6Psrwa0aAAB8izAiyeVirhEAAGwhjHyPTqwAANhBGPkeLSMAANhBGPkeLSMAANhxSmFk9uzZ6tWrl8LCwpScnKzVq1c3eOz5558vl8t13HLJJZecctHNISrKrEtL7dYBAECg8TqMZGdnKyMjQ9OnT1d+fr4SExM1btw4lZSU1Hv8woULtWvXLveybt06BQcH6xe/+MUPLr4pde5s1vv22a0DAIBA43UYmTlzpiZPnqz09HQlJCRozpw5Cg8P17x58+o9vnPnzoqNjXUvS5cuVXh4uN+FkU6dzHrvXrt1AAAQaLwKI5WVlcrLy1NqamrtGwQFKTU1Vbm5uY16j6efflpXXXWV2rdv3+AxFRUVKisr81iaGy0jAADY4VUY2bNnj6qqqhQTE+OxPyYmRkVFRSc9f/Xq1Vq3bp2uv/76Ex6XlZWlqKgo9xIfH+9NmaeElhEAAOzw6Wiap59+WoMHD9aIESNOeFxmZqZKS0vdy86dO5u9NlpGAACwo403B0dHRys4OFjFxcUe+4uLixUbG3vCc8vLyzV//nw98MADJ/05oaGhCg0N9aa0H4yWEQAA7PCqZSQkJERJSUnKyclx76uurlZOTo5SUlJOeO6CBQtUUVGha6+99tQqbWa0jAAAYIdXLSOSlJGRoUmTJmn48OEaMWKEZs2apfLycqWnp0uSJk6cqO7duysrK8vjvKefflqXX365TjvttKapvInRMgIAgB1eh5G0tDTt3r1b06ZNU1FRkYYOHaolS5a4O7UWFhYqKMizwaWgoEArVqzQ22+/3TRVN4OaMLJvn+Q45uF5AACg+bkcx3FsF3EyZWVlioqKUmlpqSIjI5vlZxw4INW8dXm5FB7eLD8GAICA0di/3zyb5nsREVJwsNnmVg0AAL5DGPmey0UnVgAAbCCM1EEnVgAAfI8wUgctIwAA+B5hpA5aRgAA8D3CSB20jAAA4HuEkTpoGQEAwPcII3XQMgIAgO8RRuqgZQQAAN8jjNRBywgAAL5HGKmj7vNpAACAbxBG6qh5oPCePXbrAAAgkBBG6uja1ayLi+3WAQBAICGM1BETY9aHDpkn9wIAgOZHGKkjIkJq185s0zoCAIBvEEbqcLm4VQMAgK8RRo5Rc6umpMRuHQAABArCyDFqwggtIwAA+AZh5BjcpgEAwLcII8fgNg0AAL5FGDkGt2kAAPAtwsgxuE0DAIBvEUaOwW0aAAB8izByDG7TAADgW4SRY9Tcptm3T6qstFsLAACBgDByjM6dpeBgs717t91aAAAIBISRYwQF0YkVAABfIozUgzACAIDvEEbqERdn1rt22a0DAIBAQBipR48eZr1zp906AAAIBISResTHmzVhBACA5kcYqQdhBAAA3yGM1IMwAgCA7xBG6lE3jDiO3VoAAGjtCCP1qAkjBw9KpaV2awEAoLUjjNQjPNzMxCpxqwYAgOZ2SmFk9uzZ6tWrl8LCwpScnKzVq1ef8Pj9+/dr6tSpiouLU2hoqM4880y98cYbp1Swr9BvBAAA3/A6jGRnZysjI0PTp09Xfn6+EhMTNW7cOJWUlNR7fGVlpS688ELt2LFDL7/8sgoKCjR37lx17979BxffnAgjAAD4RhtvT5g5c6YmT56s9PR0SdKcOXP0+uuva968ebrrrruOO37evHnau3evVq1apbZt20qSevXq9cOq9gHCCAAAvuFVy0hlZaXy8vKUmppa+wZBQUpNTVVubm695/zvf/9TSkqKpk6dqpiYGA0aNEgPP/ywqqqqGvw5FRUVKisr81h8jTACAIBveBVG9uzZo6qqKsXExHjsj4mJUVFRUb3nbNu2TS+//LKqqqr0xhtv6N5779Vjjz2mP/3pTw3+nKysLEVFRbmX+Jpk4EOEEQAAfKPZR9NUV1era9eu+sc//qGkpCSlpaXp7rvv1pw5cxo8JzMzU6Wlpe5lp4VEcPrpZl1Y6PMfDQBAQPGqz0h0dLSCg4NVXFzssb+4uFixsbH1nhMXF6e2bdsqODjYvW/gwIEqKipSZWWlQkJCjjsnNDRUoaGh3pTW5Pr0Mesvv5SOHpXaeN27BgAANIZXLSMhISFKSkpSTk6Oe191dbVycnKUkpJS7zmjRo3Sli1bVF1d7d73xRdfKC4urt4g4i+6dZPCwkwQoXUEAIDm4/VtmoyMDM2dO1fPPfecNm7cqClTpqi8vNw9umbixInKzMx0Hz9lyhTt3btXt9xyi7744gu9/vrrevjhhzV16tSm+xTNIChI6tvXbG/ZYrcWAABaM69vPqSlpWn37t2aNm2aioqKNHToUC1ZssTdqbWwsFBBQbUZJz4+Xm+99ZZuvfVWDRkyRN27d9ctt9yiO++8s+k+RTPp21dav96EkbFjbVcDAEDr5HIc/38UXFlZmaKiolRaWqrIyEif/dzbbpNmzpRuvdWsAQBA4zX27zfPpjmBM84wa27TAADQfAgjJ1ATRrZutVsHAACtGWHkBGo6sG7dKtUZDAQAAJoQYeQETj/dzC9SUSF9/bXtagAAaJ0IIyfQpo3Uu7fZpt8IAADNgzByEv36mXVBgd06AABorQgjJ5GQYNbr19utAwCA1oowchKDBpk1YQQAgOZBGDmJs84y63Xr7NYBAEBrRRg5iYEDJZdL2r1bKimxXQ0AAK0PYeQk2revHVHDrRoAAJoeYaQR6DcCAEDzIYw0Av1GAABoPoSRRqBlBACA5kMYaYTBg836s894Rg0AAE2NMNIIAwdKYWHSgQNMCw8AQFMjjDRCmzbS0KFmOy/PaikAALQ6hJFGSkoy608+sVsHAACtDWGkkWrCCC0jAAA0LcJIIw0fbtb5+XRiBQCgKRFGGmngQKldO9OJdfNm29UAANB6EEYaqU0bKTHRbH/8sd1aAABoTQgjXkhJMeuVK+3WAQBAa0IY8cI555j1ihV26wAAoDUhjHhh1CizXrdO2rfPbi0AALQWhBEvxMRI/fqZ7VWr7NYCAEBrQRjxErdqAABoWoQRL9WEkQ8+sFsHAACtBWHES6NHm/Xq1dLBg3ZrAQCgNSCMeKlvX6lnT+nIEen9921XAwBAy0cY8ZLLJV14odl+5x27tQAA0BoQRk5BTRhZutRuHQAAtAaEkVPwk5+YFpJ166Rdu2xXAwBAy0YYOQXR0dKwYWb77bft1gIAQEtHGDlFP/2pWb/2mt06AABo6Qgjp+iyy8x6yRKposJuLQAAtGSEkVOUlCTFxZm5RpYts10NAAAt1ymFkdmzZ6tXr14KCwtTcnKyVq9e3eCxzz77rFwul8cSFhZ2ygX7i6Agafx4s/2//9mtBQCAlszrMJKdna2MjAxNnz5d+fn5SkxM1Lhx41RSUtLgOZGRkdq1a5d7+fLLL39Q0f6i5lbN4sVSdbXdWgAAaKm8DiMzZ87U5MmTlZ6eroSEBM2ZM0fh4eGaN29eg+e4XC7Fxsa6l5iYmB9UtL8YM0aKjJS+/lrKzbVdDQAALZNXYaSyslJ5eXlKTU2tfYOgIKWmpir3BH+NDx48qJ49eyo+Pl4TJkzQ+vXrT/hzKioqVFZW5rH4o7AwacIEsz1/vt1aAABoqbwKI3v27FFVVdVxLRsxMTEqKiqq95z+/ftr3rx5Wrx4sf71r3+purpaI0eO1FdffdXgz8nKylJUVJR7iY+P96ZMn7rqKrN++WWpqspuLQAAtETNPpomJSVFEydO1NChQ3Xeeedp4cKF6tKli5566qkGz8nMzFRpaal72blzZ3OXecpSU6VOnaSiImn5ctvVAADQ8ngVRqKjoxUcHKzi4mKP/cXFxYqNjW3Ue7Rt21bDhg3Tli1bGjwmNDRUkZGRHou/CgmRfv5zs/3CC3ZrAQCgJfIqjISEhCgpKUk5OTnufdXV1crJyVFKSkqj3qOqqkqff/654uLivKvUj02aZNYLFph5RwAAQON5fZsmIyNDc+fO1XPPPaeNGzdqypQpKi8vV3p6uiRp4sSJyszMdB//wAMP6O2339a2bduUn5+va6+9Vl9++aWuv/76pvsUlo0cKfXrJ5WXm74jAACg8dp4e0JaWpp2796tadOmqaioSEOHDtWSJUvcnVoLCwsVFFSbcfbt26fJkyerqKhInTp1UlJSklatWqWEhISm+xSWuVzSr34l3X239MwzZhsAADSOy3Ecx3YRJ1NWVqaoqCiVlpb6bf+Rr76SevY0k59t2CANHGi7IgAA7Grs32+eTdNEevSonZH1ySft1gIAQEtCGGlCN91k1s89R0dWAAAaizDShMaMkc48Uyork55/3nY1AAC0DISRJhQUJP3+92b7L3+Rjh61Ww8AAC0BYaSJpadLXbpI27dL2dm2qwEAwP8RRppYeLj0hz+Y7RkzzOgaAADQMMJIM7jpJqlDB2ndOun1121XAwCAfyOMNIOOHWtH1mRlSf4/kwsAAPYQRprJH/4ghYZKubk8zRcAgBMhjDST2Fip5vE7mZm0jgAA0BDCSDO6+27TofXDD6WFC21XAwCAfyKMNKO4OOn22812ZqZ05IjdegAA8EeEkWZ2++1S167S5s3SP/9puxoAAPwPYaSZdeggTZtmtu+7TzpwwGo5AAD4HcKID9xwg9Svn1RSIj30kO1qAADwL4QRH2jbVnrsMbP92GNmMjQAAGAQRnxk/Hjp8svNw/N++1umiQcAoAZhxIf+9jcpIkJatUp6+mnb1QAA4B8IIz4UHy898IDZ/r//k4qL7dYDAIA/IIz42O9+Jw0dKu3fL914IzOzAgBAGPGxNm2kZ54xnVr/+1+zDQBAICOMWDB0qPSnP5nt3/9e2rrVajkAAFhFGLHkttuk0aOl8nLp2mvNKBsAAAIRYcSS4GDp+eelyEjzIL377rNdEQAAdhBGLOrZU5ozx2w/9JD02mt26wEAwAbCiGVXXy1NnWq2r7tO2rbNbj0AAPgaYcQPzJwp/fjHZrjvz38uHT5suyIAAHyHMOIHQkKkBQukLl2kTz+VJk9m/hEAQOAgjPiJHj2k7GwzD8m//1079BcAgNaOMOJHLrhA+vvfzfa0aSacAADQ2hFG/MzkyWYOEkmaNEnKzbVbDwAAzY0w4oceeUS67DKpokK69FJpwwbbFQEA0HwII34oOFh68UUpOVnau1caN04qLLRdFQAAzYMw4qfat5def10aOFD66itp7Fhpzx7bVQEA0PQII37stNOkt94yI20KCqTUVOnbb21XBQBA0yKM+Ln4eGnpUikmRvrsM2nMGAIJAKB1IYy0AAMGSO++WxtIaCEBALQmpxRGZs+erV69eiksLEzJyclavXp1o86bP3++XC6XLr/88lP5sQEtIcEEkq5dpTVrpAsvNJ1bAQBo6bwOI9nZ2crIyND06dOVn5+vxMREjRs3TiUlJSc8b8eOHbr99tt17rnnnnKxgS4hQXrvPRNIPv3U3LIpLrZdFQAAP4zXYWTmzJmaPHmy0tPTlZCQoDlz5ig8PFzz5s1r8Jyqqipdc801uv/++9WnT58fVHCgqxtI1qyRzjlH2r7ddlUAAJw6r8JIZWWl8vLylJqaWvsGQUFKTU1V7gmmCn3ggQfUtWtX/eY3v2nUz6moqFBZWZnHgloJCdKKFVKvXtKWLdKoUdLnn9uuCgCAU+NVGNmzZ4+qqqoUExPjsT8mJkZFRUX1nrNixQo9/fTTmjt3bqN/TlZWlqKiotxLfHy8N2UGhH79pJUrpUGDpF27pNGjTUABAKCladbRNAcOHNB1112nuXPnKjo6utHnZWZmqrS01L3s3LmzGatsubp1k95/37SM7N9vOrUuXmy7KgAAvNPGm4Ojo6MVHBys4mN6TRYXFys2Nva447du3aodO3Zo/Pjx7n3V1dXmB7dpo4KCAvXt2/e480JDQxUaGupNaQGrUyfp7bel//f/zIytP/uZ9Oij5mF7Lpft6gAAODmvWkZCQkKUlJSknJwc977q6mrl5OQoJSXluOMHDBigzz//XGvWrHEvl112mS644AKtWbOG2y9NJDxcWrRIuvFGyXGkO+4wT/+trLRdGQAAJ+dVy4gkZWRkaNKkSRo+fLhGjBihWbNmqby8XOnp6ZKkiRMnqnv37srKylJYWJgGDRrkcX7Hjh0l6bj9+GHatpX+/nfzLJtbb5Weftp0bn3lFTOtPAAA/srrMJKWlqbdu3dr2rRpKioq0tChQ7VkyRJ3p9bCwkIFBTGxqw0ul/T730tnnCFddZW0fLl58u+iRdLgwbarAwCgfi7HcRzbRZxMWVmZoqKiVFpaqsjISNvltAjr1kmXXip9+aXUrp00d650zTW2qwIABJLG/v2mCaOVGjRI+uQTaexY6fBh6dprpZtvph8JAMD/EEZaseho6Y03pHvuMf+ePVs67zyJkdIAAH9CGGnlgoOlBx+UXn1V6thR+vBDKTFRWrjQdmUAABiEkQBx6aVSXp40fLi0b5905ZXSb38rlZfbrgwAEOgIIwGkTx8zhfydd5qRN//4hwkna9bYrgwAEMgIIwEmJESaMUNaulSKi5M2bTLDf2fNkr6fHBcAAJ8ijASoMWOktWulyy4zI2xuvVUaN84MBQYAwJcIIwEsOlr673+lJ580c5G8844ZEjxnjplWHgAAXyCMBDiXyzzT5rPPpHPOkQ4elKZMkVJTpR07bFcHAAgEhBFIkvr1M9PHz5plWknefde0kjz5JH1JAADNizACt6Ag6ZZbaltJysulm26Szj9f2rDBdnUAgNaKMILj1LSS/PWvUni49MEHZqK0P/5ROnTIdnUAgNaGMIJ6BQWZJwBv2GBG3Bw9KmVlSWedJb3+uu3qAACtCWEEJ9Szp7R4sRl1Ex9vOrVeeqmZwZVn3AAAmgJhBI0yYYJpJbnjDvO8m4ULpQEDpD/9yTwVGACAU0UYQaNFREiPPirl55sOrocOSffeKyUkSK+8wtwkAIBTQxiB14YMkd5/X5o/v/bWzc9/XjurKwAA3iCM4JS4XFJamnm2zbRpUliY9N570rBhZhK1oiLbFQIAWgrCCH6Q8HDp/vtNKPnFL8wEaU89JZ1xhnTffdKBA7YrBAD4O8IImkTPntJLL5nbN8nJZsK0++83oeTJJ6UjR2xXCADwV4QRNKlzz5Vyc6UFC0wQKSkxs7gOGiQtWkQnVwDA8QgjaHIul+nQumGD9MQTUpcu0hdfSFdcIY0aZfqWAABQgzCCZtO2rTR1qrRli3TPPeYBfLm50k9+YpaVK21XCADwB4QRNLvISOnBB00omTrVhJT33jNzlVx0kbR6te0KAQA2EUbgM926mds2W7ZIkydLbdpIb71lOrxedpm0Zo3tCgEANhBG4HOnny794x9SQYE0aZJ5KN+rr5o5Sn72M+mTT2xXCADwJcIIrOnTR3r2WdPR9eqrTcfX//5XOvtsadw4M0wYAND6EUZgXf/+0osvSuvXS9ddZx7E9/bb0nnnmaHCS5YwJBgAWjPCCPzGwIHS88+bYcC//a0UEiKtWCFdfLE0fLh5GF9Vle0qAQBNjTACv9OnjzRnjrRtm5SRYaacz883c5cMGCDNnm1meAUAtA6EEfit7t2lxx6TvvzSzFPSqZMZiXPzzaYT7D338EA+AGgNCCPwe9HRZp6SwkLp8cdNy8nevdJDD5ln4vz619K6dbarBACcKsIIWoyICNMq8sUX0ssvSykpUmWl9Mwz0uDB0tix0v/+R78SAGhpCCNocYKDpSuvlFatMsuVV5q5SpYulSZMkPr2lWbMkHbvtl0pAKAxCCNo0VJSTCvJli3SHXdInTubPiaZmVKPHtLEidJHHzE0GAD8GWEErULv3tKjj0pffWVu2wwfbm7hvPCC9OMfm4nUnnlGOnzYdqUAgGOdUhiZPXu2evXqpbCwMCUnJ2v1CZ50tnDhQg0fPlwdO3ZU+/btNXToUL3wwgunXDBwIu3aSb/6lfTxx6ZFZOJEKTRUysszHV27d5d+/3tp7VrblQIAangdRrKzs5WRkaHp06crPz9fiYmJGjdunEpKSuo9vnPnzrr77ruVm5urtWvXKj09Xenp6Xrrrbd+cPHAiYwYIT33nGktmTFD6tVL2rfPjMhJTDSv/+MfUlmZ7UoBILC5HMe7u+nJyck6++yz9cQTT0iSqqurFR8fr9/97ne66667GvUeP/rRj3TJJZfowQcfbNTxZWVlioqKUmlpqSIjI70pF3CrqpJycqR//tM8A+fIEbM/PFxKS5Ouv970QXG5rJYJAK1GY/9+e9UyUllZqby8PKWmpta+QVCQUlNTlZube9LzHcdRTk6OCgoKNHr0aG9+NPCDBQeb4b8vvSR9/bWZUG3gQOnQIdOfZNQo6ayzpJkzGYkDAL7kVRjZs2ePqqqqFBMT47E/JiZGRSeYCrO0tFQREREKCQnRJZdcoscff1wXXnhhg8dXVFSorKzMYwGaUpcuZqr59eullSul9HTTQrJxo3TbbaZvyc9+Ji1aJFVU2K4WAFo3n4ym6dChg9asWaOPP/5YDz30kDIyMrRs2bIGj8/KylJUVJR7iY+P90WZCEAulzRypDRvnrRrl/TUU2bkzZEj5lbOFVdIcXHSTTdJubkMEQaA5uBVn5HKykqFh4fr5Zdf1uWXX+7eP2nSJO3fv1+LFy9u1Ptcf/312rlzZ4OdWCsqKlRR539Hy8rKFB8fT58R+My6dWZY8L/+JX3zTe3+M84wI3SuvdYMJwYANKxZ+oyEhIQoKSlJOTk57n3V1dXKyclRSkpKo9+nurraI2wcKzQ0VJGRkR4L4EuDBkmPPGKeh7N0qXTddeY2zpYt0rRp5vk4o0dLc+dK+/fbrhYAWjavb9NkZGRo7ty5eu6557Rx40ZNmTJF5eXlSk9PlyRNnDhRmZmZ7uOzsrK0dOlSbdu2TRs3btRjjz2mF154Qddee23TfQqgmQQHS6mp0vPPS8XFZp2aam7vfPCBdMMNUkyMdPnl0n/+Ix08aLtiAGh52nh7Qlpamnbv3q1p06apqKhIQ4cO1ZIlS9ydWgsLCxUUVJtxysvLddNNN+mrr75Su3btNGDAAP3rX/9SWlpa030KwAciIkwLyXXXmblLXnzRhJP166XFi83Srp106aVmqPBPf2r+DQA4Ma/nGbGBeUbgz9atk+bPl7KzzW2cGhER5sF9aWlmSHFoqL0aAcCGxv79JowATcRxpPx8E0qys01/kxodO5qhwr/4hfSTnxBMAAQGwghgUXW1eTbO/PnSggVm2HCNyEhzK+fKK6Vx46T27e3VCQDNiTAC+ImqKtPZ9aWXzCRqdecHbNdOuvhiM5/JpZdKUVH26gSApkYYAfxQdbX04YfSK69ICxdKO3bUvta2rRmpc8UVpq9Jly7WygSAJkEYAfyc40hr1phQ8sorZir6GkFBZh6TCROk8eOlvn2tlQkAp4wwArQwGzea2zivvGI6wtY1cKAJJePHmycLBwfbqREAvEEYAVqwHTvMs3FefVV6/33p6NHa1047zcxhMn686QDLrwQAf0UYAVqJ/fulJUtMMHnzTWnfvtrX2raVzjuvttWE5+UA8CeEEaAVOnpUWrnSBJNXX5W++MLz9bPOMqHk4ovN7Zy2be3UCQASYQQICF98URtMVqwww4hrREaa0TkXXyxddJHUo4e9OgEEJsIIEGD27jW3c954Q3rrLWnPHs/XBw0yweTii6VRo6SQEDt1AggchBEggFVVSXl5Jpy8+aaZDbbub3pEhDRmTG2rSc+e9moF0HoRRgC4ffuttHSpCSZLlkglJZ6vDxxoRuakppoOsRERduoE0LoQRgDUq7raTLZWE0xycz37mrRpYzq/XnihCSdnn232AYC3CCMAGmXfPumdd8yydKm0fbvn65GR0gUXmGCSmir17y+5XHZqBdCyEEYAnJJt22qDybvvmo6xdfXoURtMUlOlmBg7dQLwf4QRAD9YVZW5pbN0qQkoK1ZIFRWexyQkSOefb1pPzjuPB/wBqEUYAdDkDh82gaTmts6xz9CRzBDiCy4wy+jRZvp6AIGJMAKg2X37rXl2znvvmWXdOs/XXS5pyJDalpPRo6VOnayUCsACwggAn9u9W1q+3ASTZcukDRs8X3e5pKFDTTA5/3wTTqKiLBQKwCcIIwCsKy6uDSfvvScVFHi+HhRkwsno0dK555qFPidA60EYAeB3du0yLSY1LSebNx9/zIABtcFk9GhmhwVaMsIIAL/39demz8kHH5jl2D4nkhQfXxtMzj3XzBbLPCdAy0AYAdDifPuttHKlCSbvv29G6xw96nnMaafVtpyce640bBgzxAL+ijACoMUrL5c+/LA2nHz4oRleXFf79tLIkbXhZMQIKTzcTr0APBFGALQ6lZWmtaQmnKxYIe3f73lMmzamtWTkSGnUKLPu3t1KuUDAI4wAaPWqq6X162vDyQcfSN98c/xxp59eG0xGjjRzn3BrB2h+hBEAAcdxpMJCadUqs6xcKX32mQktdbVvLyUn17ae/PjHUseOVkoGWjXCCABIOnhQ+uij2oCSmyuVlnoe43KZZ+yMGiWlpJig0r+/mQcFwKkjjABAPaqrzcywNS0nq1ZJW7Ycf1xUlOkMm5xcuzAhG+AdwggANFJxsWkxWbnSjNjJyzt+1I4k9e7tGU6GDZPCwnxfL9BSEEYA4BQdOWImYPvoo9pl48bjj2vbVkpM9Awo/foxKRtQgzACAE1o/37p4489A8ru3ccf17mzNHy459KjBwEFgYkwAgDNyHGkHTs8w0l+vlRRcfyxXbseH1Di4nxeMuBzhBEA8LHKSmntWumTT2qXdeukqqrjj+3WzTOcJCWZ0AK0JoQRAPADhw+buU7y8moDyoYNx899IpnJ2ZKSPAPKaaf5vmagqRBGAMBPlZdLa9Z4tqAUFJhbP8fq3dsEkx/9yCzDhjHEGC1Hs4aR2bNn689//rOKioqUmJioxx9/XCNGjKj32Llz5+r555/Xuu+fDZ6UlKSHH364wePrQxgB0NqVlUmffuoZUOqb/0Qyz9oZNsxz6dmTTrLwP80WRrKzszVx4kTNmTNHycnJmjVrlhYsWKCCggJ1reeG5zXXXKNRo0Zp5MiRCgsL0yOPPKJFixZp/fr16t7Ip1cRRgAEov37TafYjz82QeXTT6XNm+tvQenUSRo61ASTmhaU/v2l4GBfVw3UarYwkpycrLPPPltPPPGEJKm6ulrx8fH63e9+p7vuuuuk51dVValTp0564oknNHHixEb9TMIIABgHDpg+KDXh5NNPzcMCjxw5/th27cxDAeu2oAwezERt8J3G/v326rmVlZWVysvLU2ZmpntfUFCQUlNTlZub26j3OHTokI4cOaLOnTs3eExFRYUq6oyPKysr86ZMAGi1OnSQzjnHLDUqK00gqRtQ1qwxfVNqhh3XCA6WBg40k7UlJpqwkpgoxcRwmwf2eBVG9uzZo6qqKsXExHjsj4mJ0aZNmxr1Hnfeeae6deum1NTUBo/JysrS/fff701pABCwQkJqWz5qVFebPif5+Z4hZc8eM9x43Trp3/+uPb5Ll9pgMmSIWRISpNBQ338eBB6vwsgPNWPGDM2fP1/Lli1T2AnaCTMzM5WRkeH+d1lZmeLj431RIgC0CkFB0plnmuWqq8w+x5G+/tq0mnz2mZkTZe1a6YsvzGyyOTlmqREcLA0Y4BlQEhPNhG20oqApeRVGoqOjFRwcrOLiYo/9xcXFio2NPeG5f/nLXzRjxgy98847GjJkyAmPDQ0NVShxHACalMtlpqbv0UO69NLa/YcOmblPagJKzXrfPnP7Z/166cUXa48/7TTPgDJkiLn1Ex7u+8+E1sGrMBISEqKkpCTl5OTo8ssvl2Q6sObk5Ojmm29u8LxHH31UDz30kN566y0NHz78BxUMAGha4eG1E63VcBzpq69qW09qAkpBgfTtt9K775qlhssl9e0rDRrkufTrZ24jASdySkN7J02apKeeekojRozQrFmz9NJLL2nTpk2KiYnRxIkT1b17d2VlZUmSHnnkEU2bNk0vvviiRo0a5X6fiIgIRURENOpnMpoGAPzD4cPHt6J8/rkJKPVp08YMMT42pPTuzbDjQNAso2kkKS0tTbt379a0adNUVFSkoUOHasmSJe5OrYWFhQoKCnIf/+STT6qyslI///nPPd5n+vTpuu+++7z98QAAi9q1M9PUJyXV7nMcqaSktmNszbJ+vRmKXHOrJzvb830SEqSzzvIMKTzhODAxHTwAoFk4jrRz5/EBZcMG6bvv6j8nMrI2mNQNKl26EFJaIp5NAwDwS1VV0rZtx4eUggLp6NH6z+nc2bSkDBzouaYlxb8RRgAALUplpRlmfGxI2bq1/inwJSkiwgSTY0MKfVL8A2EEANAqHD5sWk02bjS3eGrWmzc33JISGmo6zh4bUhjd41uEEQBAq3bkiJll9tiQsmlTw31SgoOlM87wDCkDB5rJ3dq39239gYAwAgAISFVV0pdfHh9SNm6UTvSos549TUDp398sAwaYdWws/VJOFWEEAIA6HEf65pvjQ8qGDeaZPQ2JjKwNKHVDSr9+PAH5ZAgjAAA00p49teGkoKB22b7dPHSwPi6XaU2pCSd1wwrP7zEIIwAA/EAVFaZfSk042bSpdnv//obP69DBPKTw2KBy5plmwrdAQRgBAKCZ1Mw6W19I2bbtxK0pp5/uGU769TNLz56tbzgyYQQAAAsqKszcKPUFlX37Gj6vbVvzsMGacFKznHmm1L27VOdJKy1Gsz2bBgAANCw01IzKSUjw3O84pm9K3XCyebNZtmwxk75t2mSWY4WFmSHJx4aUfv1ax2gfWkYAALCsqso8x6cmnNQsX3xhOtE2NLmbZGahrQkqdW/79OsnRUfbDSrcpgEAoBU4elTaseP4kLJ5s5lPpaH+KZIUFVUbUs44wyx9+5q1Lx4+SBgBAKCVq6gwLSf1BZWdO098bk2LSk04+c1vTHBpSoQRAAAC2OHDpiNt3X4pW7ea9c6dxz98cOVKaeTIpq2BDqwAAASwdu2kQYPMcqyaFpW6AaV/f9/XWIMwAgBAgAkNNROyDRhguxKjBY5aBgAArQlhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYFWLeGqv4ziSpLKyMsuVAACAxqr5u13zd7whLSKMHDhwQJIUHx9vuRIAAOCtAwcOKCoqqsHXXc7J4oofqK6u1jfffKMOHTrI5XI12fuWlZUpPj5eO3fuVGRkZJO9b2vF9Wo8rlXjca28w/VqPK6Vd5rjejmOowMHDqhbt24KCmq4Z0iLaBkJCgpSjx49mu39IyMj+aJ6gevVeFyrxuNaeYfr1XhcK+809fU6UYtIDTqwAgAAqwgjAADAqoAOI6GhoZo+fbpCQ0Ntl9IicL0aj2vVeFwr73C9Go9r5R2b16tFdGAFAACtV0C3jAAAAPsIIwAAwCrCCAAAsIowAgAArAroMDJ79mz16tVLYWFhSk5O1urVq22XZN19990nl8vlsQwYMMD9+nfffaepU6fqtNNOU0REhK688koVFxdbrNh33n//fY0fP17dunWTy+XSf//7X4/XHcfRtGnTFBcXp3bt2ik1NVWbN2/2OGbv3r265pprFBkZqY4dO+o3v/mNDh486MNP4Tsnu16/+tWvjvuuXXTRRR7HBMr1ysrK0tlnn60OHTqoa9euuvzyy1VQUOBxTGN+9woLC3XJJZcoPDxcXbt21R133KGjR4/68qM0u8Zcq/PPP/+479aNN97ocUwgXCtJevLJJzVkyBD3RGYpKSl688033a/7y/cqYMNIdna2MjIyNH36dOXn5ysxMVHjxo1TSUmJ7dKsO+uss7Rr1y73smLFCvdrt956q1599VUtWLBAy5cv1zfffKMrrrjCYrW+U15ersTERM2ePbve1x999FH97W9/05w5c/TRRx+pffv2GjdunL777jv3Mddcc43Wr1+vpUuX6rXXXtP777+vG264wVcfwadOdr0k6aKLLvL4rv3nP//xeD1Qrtfy5cs1depUffjhh1q6dKmOHDmisWPHqry83H3MyX73qqqqdMkll6iyslKrVq3Sc889p2effVbTpk2z8ZGaTWOulSRNnjzZ47v16KOPul8LlGslST169NCMGTOUl5enTz75RD/5yU80YcIErV+/XpIffa+cADVixAhn6tSp7n9XVVU53bp1c7KysixWZd/06dOdxMTEel/bv3+/07ZtW2fBggXufRs3bnQkObm5uT6q0D9IchYtWuT+d3V1tRMbG+v8+c9/du/bv3+/Exoa6vznP/9xHMdxNmzY4EhyPv74Y/cxb775puNyuZyvv/7aZ7XbcOz1chzHmTRpkjNhwoQGzwnk61VSUuJIcpYvX+44TuN+99544w0nKCjIKSoqch/z5JNPOpGRkU5FRYVvP4APHXutHMdxzjvvPOeWW25p8JxAvVY1OnXq5Pzzn//0q+9VQLaMVFZWKi8vT6mpqe59QUFBSk1NVW5ursXK/MPmzZvVrVs39enTR9dcc40KCwslSXl5eTpy5IjHdRswYIBOP/30gL9u27dvV1FRkce1iYqKUnJysvva5ObmqmPHjho+fLj7mNTUVAUFBemjjz7yec3+YNmyZeratav69++vKVOm6Ntvv3W/FsjXq7S0VJLUuXNnSY373cvNzdXgwYMVExPjPmbcuHEqKytz/19wa3Tstarx73//W9HR0Ro0aJAyMzN16NAh92uBeq2qqqo0f/58lZeXKyUlxa++Vy3iQXlNbc+ePaqqqvK4uJIUExOjTZs2WarKPyQnJ+vZZ59V//79tWvXLt1///0699xztW7dOhUVFSkkJEQdO3b0OCcmJkZFRUV2CvYTNZ+/vu9UzWtFRUXq2rWrx+tt2rRR586dA/L6XXTRRbriiivUu3dvbd26VX/84x918cUXKzc3V8HBwQF7vaqrq/WHP/xBo0aN0qBBgySpUb97RUVF9X7/al5rjeq7VpL0y1/+Uj179lS3bt20du1a3XnnnSooKNDChQslBd61+vzzz5WSkqLvvvtOERERWrRokRISErRmzRq/+V4FZBhBwy6++GL39pAhQ5ScnKyePXvqpZdeUrt27SxWhtbmqquucm8PHjxYQ4YMUd++fbVs2TKNGTPGYmV2TZ06VevWrfPoq4X6NXSt6vYrGjx4sOLi4jRmzBht3bpVffv29XWZ1vXv319r1qxRaWmpXn75ZU2aNEnLly+3XZaHgLxNEx0dreDg4ON6DBcXFys2NtZSVf6pY8eOOvPMM7VlyxbFxsaqsrJS+/fv9ziG6yb35z/Rdyo2Nva4DtJHjx7V3r17A/76SVKfPn0UHR2tLVu2SArM63XzzTfrtdde03vvvacePXq49zfmdy82Nrbe71/Na61NQ9eqPsnJyZLk8d0KpGsVEhKiM844Q0lJScrKylJiYqL++te/+tX3KiDDSEhIiJKSkpSTk+PeV11drZycHKWkpFiszP8cPHhQW7duVVxcnJKSktS2bVuP61ZQUKDCwsKAv269e/dWbGysx7UpKyvTRx995L42KSkp2r9/v/Ly8tzHvPvuu6qurnb/xzKQffXVV/r2228VFxcnKbCul+M4uvnmm7Vo0SK9++676t27t8frjfndS0lJ0eeff+4R4JYuXarIyEglJCT45oP4wMmuVX3WrFkjSR7frUC4Vg2prq5WRUWFf32vmqwrbAszf/58JzQ01Hn22WedDRs2ODfccIPTsWNHjx7Dgei2225zli1b5mzfvt1ZuXKlk5qa6kRHRzslJSWO4zjOjTfe6Jx++unOu+++63zyySdOSkqKk5KSYrlq3zhw4IDz6aefOp9++qkjyZk5c6bz6aefOl9++aXjOI4zY8YMp2PHjs7ixYudtWvXOhMmTHB69+7tHD582P0eF110kTNs2DDno48+clasWOH069fPufrqq219pGZ1out14MAB5/bbb3dyc3Od7du3O++8847zox/9yOnXr5/z3Xffud8jUK7XlClTnKioKGfZsmXOrl273MuhQ4fcx5zsd+/o0aPOoEGDnLFjxzpr1qxxlixZ4nTp0sXJzMy08ZGazcmu1ZYtW5wHHnjA+eSTT5zt27c7ixcvdvr06eOMHj3a/R6Bcq0cx3HuuusuZ/ny5c727dudtWvXOnfddZfjcrmct99+23Ec//leBWwYcRzHefzxx53TTz/dCQkJcUaMGOF8+OGHtkuyLi0tzYmLi3NCQkKc7t27O2lpac6WLVvcrx8+fNi56aabnE6dOjnh4eHOz372M2fXrl0WK/ad9957z5F03DJp0iTHcczw3nvvvdeJiYlxQkNDnTFjxjgFBQUe7/Htt986V199tRMREeFERkY66enpzoEDByx8muZ3out16NAhZ+zYsU6XLl2ctm3bOj179nQmT5583P8MBMr1qu86SXKeeeYZ9zGN+d3bsWOHc/HFFzvt2rVzoqOjndtuu805cuSIjz9N8zrZtSosLHRGjx7tdO7c2QkNDXXOOOMM54477nBKS0s93icQrpXjOM6vf/1rp2fPnk5ISIjTpUsXZ8yYMe4g4jj+871yOY7jNF07CwAAgHcCss8IAADwH4QRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVv1/8+g4zjSrAhEAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 300: loss is 0.15571\n",
            "Epoch 301: loss is 0.15527\n",
            "Epoch 302: loss is 0.15483\n",
            "Epoch 303: loss is 0.15440\n",
            "Epoch 304: loss is 0.15396\n",
            "Epoch 305: loss is 0.15353\n",
            "Epoch 306: loss is 0.15310\n",
            "Epoch 307: loss is 0.15267\n",
            "Epoch 308: loss is 0.15224\n",
            "Epoch 309: loss is 0.15182\n",
            "Epoch 310: loss is 0.15139\n",
            "Epoch 311: loss is 0.15097\n",
            "Epoch 312: loss is 0.15055\n",
            "Epoch 313: loss is 0.15013\n",
            "Epoch 314: loss is 0.14971\n",
            "Epoch 315: loss is 0.14929\n",
            "Epoch 316: loss is 0.14887\n",
            "Epoch 317: loss is 0.14845\n",
            "Epoch 318: loss is 0.14804\n",
            "Epoch 319: loss is 0.14762\n",
            "Epoch 320: loss is 0.14721\n",
            "Epoch 321: loss is 0.14680\n",
            "Epoch 322: loss is 0.14639\n",
            "Epoch 323: loss is 0.14599\n",
            "Epoch 324: loss is 0.14558\n",
            "Epoch 325: loss is 0.14517\n",
            "Epoch 326: loss is 0.14477\n",
            "Epoch 327: loss is 0.14436\n",
            "Epoch 328: loss is 0.14396\n",
            "Epoch 329: loss is 0.14356\n",
            "Epoch 330: loss is 0.14316\n",
            "Epoch 331: loss is 0.14277\n",
            "Epoch 332: loss is 0.14237\n",
            "Epoch 333: loss is 0.14198\n",
            "Epoch 334: loss is 0.14159\n",
            "Epoch 335: loss is 0.14119\n",
            "Epoch 336: loss is 0.14080\n",
            "Epoch 337: loss is 0.14041\n",
            "Epoch 338: loss is 0.14002\n",
            "Epoch 339: loss is 0.13964\n",
            "Epoch 340: loss is 0.13925\n",
            "Epoch 341: loss is 0.13887\n",
            "Epoch 342: loss is 0.13848\n",
            "Epoch 343: loss is 0.13810\n",
            "Epoch 344: loss is 0.13772\n",
            "Epoch 345: loss is 0.13734\n",
            "Epoch 346: loss is 0.13696\n",
            "Epoch 347: loss is 0.13658\n",
            "Epoch 348: loss is 0.13621\n",
            "Epoch 349: loss is 0.13583\n",
            "Epoch 350: loss is 0.13545\n",
            "Epoch 351: loss is 0.13508\n",
            "Epoch 352: loss is 0.13471\n",
            "Epoch 353: loss is 0.13434\n",
            "Epoch 354: loss is 0.13397\n",
            "Epoch 355: loss is 0.13360\n",
            "Epoch 356: loss is 0.13324\n",
            "Epoch 357: loss is 0.13287\n",
            "Epoch 358: loss is 0.13251\n",
            "Epoch 359: loss is 0.13214\n",
            "Epoch 360: loss is 0.13178\n",
            "Epoch 361: loss is 0.13142\n",
            "Epoch 362: loss is 0.13106\n",
            "Epoch 363: loss is 0.13070\n",
            "Epoch 364: loss is 0.13034\n",
            "Epoch 365: loss is 0.12998\n",
            "Epoch 366: loss is 0.12963\n",
            "Epoch 367: loss is 0.12927\n",
            "Epoch 368: loss is 0.12891\n",
            "Epoch 369: loss is 0.12856\n",
            "Epoch 370: loss is 0.12820\n",
            "Epoch 371: loss is 0.12785\n",
            "Epoch 372: loss is 0.12750\n",
            "Epoch 373: loss is 0.12715\n",
            "Epoch 374: loss is 0.12680\n",
            "Epoch 375: loss is 0.12646\n",
            "Epoch 376: loss is 0.12611\n",
            "Epoch 377: loss is 0.12577\n",
            "Epoch 378: loss is 0.12543\n",
            "Epoch 379: loss is 0.12509\n",
            "Epoch 380: loss is 0.12475\n",
            "Epoch 381: loss is 0.12441\n",
            "Epoch 382: loss is 0.12407\n",
            "Epoch 383: loss is 0.12374\n",
            "Epoch 384: loss is 0.12340\n",
            "Epoch 385: loss is 0.12307\n",
            "Epoch 386: loss is 0.12274\n",
            "Epoch 387: loss is 0.12240\n",
            "Epoch 388: loss is 0.12207\n",
            "Epoch 389: loss is 0.12175\n",
            "Epoch 390: loss is 0.12142\n",
            "Epoch 391: loss is 0.12109\n",
            "Epoch 392: loss is 0.12076\n",
            "Epoch 393: loss is 0.12044\n",
            "Epoch 394: loss is 0.12012\n",
            "Epoch 395: loss is 0.11979\n",
            "Epoch 396: loss is 0.11947\n",
            "Epoch 397: loss is 0.11915\n",
            "Epoch 398: loss is 0.11883\n",
            "Epoch 399: loss is 0.11850\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 400: loss is 0.11819\n",
            "Epoch 401: loss is 0.11787\n",
            "Epoch 402: loss is 0.11755\n",
            "Epoch 403: loss is 0.11724\n",
            "Epoch 404: loss is 0.11692\n",
            "Epoch 405: loss is 0.11661\n",
            "Epoch 406: loss is 0.11630\n",
            "Epoch 407: loss is 0.11598\n",
            "Epoch 408: loss is 0.11567\n",
            "Epoch 409: loss is 0.11536\n",
            "Epoch 410: loss is 0.11505\n",
            "Epoch 411: loss is 0.11474\n",
            "Epoch 412: loss is 0.11443\n",
            "Epoch 413: loss is 0.11412\n",
            "Epoch 414: loss is 0.11382\n",
            "Epoch 415: loss is 0.11351\n",
            "Epoch 416: loss is 0.11321\n",
            "Epoch 417: loss is 0.11291\n",
            "Epoch 418: loss is 0.11261\n",
            "Epoch 419: loss is 0.11231\n",
            "Epoch 420: loss is 0.11201\n",
            "Epoch 421: loss is 0.11171\n",
            "Epoch 422: loss is 0.11141\n",
            "Epoch 423: loss is 0.11111\n",
            "Epoch 424: loss is 0.11082\n",
            "Epoch 425: loss is 0.11052\n",
            "Epoch 426: loss is 0.11023\n",
            "Epoch 427: loss is 0.10994\n",
            "Epoch 428: loss is 0.10965\n",
            "Epoch 429: loss is 0.10936\n",
            "Epoch 430: loss is 0.10907\n",
            "Epoch 431: loss is 0.10878\n",
            "Epoch 432: loss is 0.10850\n",
            "Epoch 433: loss is 0.10821\n",
            "Epoch 434: loss is 0.10793\n",
            "Epoch 435: loss is 0.10764\n",
            "Epoch 436: loss is 0.10736\n",
            "Epoch 437: loss is 0.10708\n",
            "Epoch 438: loss is 0.10680\n",
            "Epoch 439: loss is 0.10652\n",
            "Epoch 440: loss is 0.10624\n",
            "Epoch 441: loss is 0.10597\n",
            "Epoch 442: loss is 0.10569\n",
            "Epoch 443: loss is 0.10541\n",
            "Epoch 444: loss is 0.10514\n",
            "Epoch 445: loss is 0.10487\n",
            "Epoch 446: loss is 0.10460\n",
            "Epoch 447: loss is 0.10433\n",
            "Epoch 448: loss is 0.10406\n",
            "Epoch 449: loss is 0.10379\n",
            "Epoch 450: loss is 0.10352\n",
            "Epoch 451: loss is 0.10325\n",
            "Epoch 452: loss is 0.10299\n",
            "Epoch 453: loss is 0.10272\n",
            "Epoch 454: loss is 0.10246\n",
            "Epoch 455: loss is 0.10219\n",
            "Epoch 456: loss is 0.10193\n",
            "Epoch 457: loss is 0.10167\n",
            "Epoch 458: loss is 0.10141\n",
            "Epoch 459: loss is 0.10115\n",
            "Epoch 460: loss is 0.10089\n",
            "Epoch 461: loss is 0.10063\n",
            "Epoch 462: loss is 0.10037\n",
            "Epoch 463: loss is 0.10011\n",
            "Epoch 464: loss is 0.09985\n",
            "Epoch 465: loss is 0.09960\n",
            "Epoch 466: loss is 0.09934\n",
            "Epoch 467: loss is 0.09909\n",
            "Epoch 468: loss is 0.09883\n",
            "Epoch 469: loss is 0.09858\n",
            "Epoch 470: loss is 0.09833\n",
            "Epoch 471: loss is 0.09808\n",
            "Epoch 472: loss is 0.09783\n",
            "Epoch 473: loss is 0.09758\n",
            "Epoch 474: loss is 0.09733\n",
            "Epoch 475: loss is 0.09709\n",
            "Epoch 476: loss is 0.09684\n",
            "Epoch 477: loss is 0.09660\n",
            "Epoch 478: loss is 0.09635\n",
            "Epoch 479: loss is 0.09611\n",
            "Epoch 480: loss is 0.09587\n",
            "Epoch 481: loss is 0.09562\n",
            "Epoch 482: loss is 0.09538\n",
            "Epoch 483: loss is 0.09514\n",
            "Epoch 484: loss is 0.09491\n",
            "Epoch 485: loss is 0.09467\n",
            "Epoch 486: loss is 0.09443\n",
            "Epoch 487: loss is 0.09419\n",
            "Epoch 488: loss is 0.09396\n",
            "Epoch 489: loss is 0.09372\n",
            "Epoch 490: loss is 0.09349\n",
            "Epoch 491: loss is 0.09325\n",
            "Epoch 492: loss is 0.09302\n",
            "Epoch 493: loss is 0.09279\n",
            "Epoch 494: loss is 0.09256\n",
            "Epoch 495: loss is 0.09233\n",
            "Epoch 496: loss is 0.09210\n",
            "Epoch 497: loss is 0.09188\n",
            "Epoch 498: loss is 0.09165\n",
            "Epoch 499: loss is 0.09143\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 500: loss is 0.09120\n",
            "Confusion matrix:\n",
            "[[0.82 0.18]\n",
            " [0.17 0.83]]\n",
            "Diagonal values:\n",
            "[0.82 0.83]\n",
            "Accuracy: \n",
            "0.8216666666666667\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    np.random.seed(2017)\n",
        "    \n",
        "    #numerical check for your layer feedforward and backpropagation\n",
        "    your_layer = Layer((60, 100), 'sigmoid')\n",
        "    unit_test_layer(your_layer)\n",
        "\n",
        "    plt.ion()\n",
        "    vehicle_classification()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOzi78Qw5Hen"
      },
      "source": [
        "### 3.4.2 MNIST Classification <a id='C3_4_2'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mnist_classification():\n",
        "    # Load data from file\n",
        "    # Make sure that fashion-mnist/*.gz is in data/\n",
        "    train_x, train_y, val_x, val_y, test_x, test_y = get_mnist_data(1)\n",
        "    train_x, val_x, test_x = normalize(train_x, train_x, test_x)    \n",
        "\n",
        "    num_class = (np.unique(train_y)).shape[0]\n",
        "\n",
        "    # Pad 1 as the third feature of train_x and test_x\n",
        "    train_x = add_one(train_x)\n",
        "    val_x = add_one(val_x)\n",
        "    test_x = add_one(test_x)\n",
        "\n",
        "    # Define hyper-parameters and train-related parameters\n",
        "    cfg = Config(num_epoch=300, learning_rate=0.001, batch_size=200, num_train=train_x.shape, visualize=False)\n",
        "\n",
        "    # Create NN classifier\n",
        "    num_hidden_nodes = 100\n",
        "    num_hidden_nodes_2 = 100\n",
        "    num_hidden_nodes_3 = 100\n",
        "    net = NeuralNet(num_class, cfg.reg)\n",
        "    net.add_linear_layer((train_x.shape[1],num_hidden_nodes), 'relu')\n",
        "    net.add_linear_layer((num_hidden_nodes, num_hidden_nodes_2), 'relu')\n",
        "    net.add_linear_layer((num_hidden_nodes_2, num_hidden_nodes_3), 'relu')\n",
        "    net.add_linear_layer((num_hidden_nodes_3, num_class), 'softmax')\n",
        "     \n",
        "    #Minibatch training - training dataset using Minibatch approach\n",
        "    minibatch_train(net, train_x, train_y, cfg)\n",
        "    \n",
        "    y_hat = net.forward(test_x)[-1]\n",
        "    test(y_hat, test_y)\n",
        "\n",
        "    metrics = confusion_matrix(test_y, net.predict(test_x))\n",
        "    print(\"Accuracy: \")\n",
        "    print(metrics.trace()/test_y.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relative error between numerical grad and function grad is: 1.332183e-09\n",
            "Reading fashion MNIST data...\n",
            "Done reading\n",
            "Epoch 1: loss is 1.19781\n",
            "Epoch 2: loss is 0.67262\n",
            "Epoch 3: loss is 0.58429\n",
            "Epoch 4: loss is 0.53838\n",
            "Epoch 5: loss is 0.50902\n",
            "Epoch 6: loss is 0.48791\n",
            "Epoch 7: loss is 0.47126\n",
            "Epoch 8: loss is 0.45801\n",
            "Epoch 9: loss is 0.44728\n",
            "Epoch 10: loss is 0.43808\n",
            "Epoch 11: loss is 0.42919\n",
            "Epoch 12: loss is 0.42241\n",
            "Epoch 13: loss is 0.41563\n",
            "Epoch 14: loss is 0.40939\n",
            "Epoch 15: loss is 0.40330\n",
            "Epoch 16: loss is 0.39797\n",
            "Epoch 17: loss is 0.39437\n",
            "Epoch 18: loss is 0.38898\n",
            "Epoch 19: loss is 0.38455\n",
            "Epoch 20: loss is 0.38036\n",
            "Epoch 21: loss is 0.37810\n",
            "Epoch 22: loss is 0.37389\n",
            "Epoch 23: loss is 0.36930\n",
            "Epoch 24: loss is 0.36661\n",
            "Epoch 25: loss is 0.36261\n",
            "Epoch 26: loss is 0.35985\n",
            "Epoch 27: loss is 0.35684\n",
            "Epoch 28: loss is 0.35387\n",
            "Epoch 29: loss is 0.35016\n",
            "Epoch 30: loss is 0.34712\n",
            "Epoch 31: loss is 0.34526\n",
            "Epoch 32: loss is 0.34333\n",
            "Epoch 33: loss is 0.33905\n",
            "Epoch 34: loss is 0.33674\n",
            "Epoch 35: loss is 0.33529\n",
            "Epoch 36: loss is 0.33329\n",
            "Epoch 37: loss is 0.32972\n",
            "Epoch 38: loss is 0.32784\n",
            "Epoch 39: loss is 0.32527\n",
            "Epoch 40: loss is 0.32333\n",
            "Epoch 41: loss is 0.32099\n",
            "Epoch 42: loss is 0.31870\n",
            "Epoch 43: loss is 0.31752\n",
            "Epoch 44: loss is 0.31535\n",
            "Epoch 45: loss is 0.31340\n",
            "Epoch 46: loss is 0.31109\n",
            "Epoch 47: loss is 0.30911\n",
            "Epoch 48: loss is 0.30649\n",
            "Epoch 49: loss is 0.30489\n",
            "Epoch 50: loss is 0.30381\n",
            "Epoch 51: loss is 0.30133\n",
            "Epoch 52: loss is 0.30001\n",
            "Epoch 53: loss is 0.29782\n",
            "Epoch 54: loss is 0.29509\n",
            "Epoch 55: loss is 0.29283\n",
            "Epoch 56: loss is 0.29221\n",
            "Epoch 57: loss is 0.29054\n",
            "Epoch 58: loss is 0.28822\n",
            "Epoch 59: loss is 0.28702\n",
            "Epoch 60: loss is 0.28568\n",
            "Epoch 61: loss is 0.28269\n",
            "Epoch 62: loss is 0.28178\n",
            "Epoch 63: loss is 0.27966\n",
            "Epoch 64: loss is 0.27814\n",
            "Epoch 65: loss is 0.27738\n",
            "Epoch 66: loss is 0.27719\n",
            "Epoch 67: loss is 0.27431\n",
            "Epoch 68: loss is 0.27296\n",
            "Epoch 69: loss is 0.27051\n",
            "Epoch 70: loss is 0.26987\n",
            "Epoch 71: loss is 0.26831\n",
            "Epoch 72: loss is 0.26675\n",
            "Epoch 73: loss is 0.26503\n",
            "Epoch 74: loss is 0.26290\n",
            "Epoch 75: loss is 0.26152\n",
            "Epoch 76: loss is 0.26088\n",
            "Epoch 77: loss is 0.25982\n",
            "Epoch 78: loss is 0.25777\n",
            "Epoch 79: loss is 0.25783\n",
            "Epoch 80: loss is 0.25539\n",
            "Epoch 81: loss is 0.25381\n",
            "Epoch 82: loss is 0.25238\n",
            "Epoch 83: loss is 0.25041\n",
            "Epoch 84: loss is 0.25010\n",
            "Epoch 85: loss is 0.24848\n",
            "Epoch 86: loss is 0.24713\n",
            "Epoch 87: loss is 0.24660\n",
            "Epoch 88: loss is 0.24484\n",
            "Epoch 89: loss is 0.24266\n",
            "Epoch 90: loss is 0.24200\n",
            "Epoch 91: loss is 0.24019\n",
            "Epoch 92: loss is 0.23882\n",
            "Epoch 93: loss is 0.23809\n",
            "Epoch 94: loss is 0.23706\n",
            "Epoch 95: loss is 0.23492\n",
            "Epoch 96: loss is 0.23410\n",
            "Epoch 97: loss is 0.23242\n",
            "Epoch 98: loss is 0.23176\n",
            "Epoch 99: loss is 0.22895\n",
            "Epoch 100: loss is 0.22913\n",
            "Epoch 101: loss is 0.22763\n",
            "Epoch 102: loss is 0.22614\n",
            "Epoch 103: loss is 0.22561\n",
            "Epoch 104: loss is 0.22386\n",
            "Epoch 105: loss is 0.22297\n",
            "Epoch 106: loss is 0.22174\n",
            "Epoch 107: loss is 0.22075\n",
            "Epoch 108: loss is 0.21942\n",
            "Epoch 109: loss is 0.21738\n",
            "Epoch 110: loss is 0.21789\n",
            "Epoch 111: loss is 0.21562\n",
            "Epoch 112: loss is 0.21368\n",
            "Epoch 113: loss is 0.21407\n",
            "Epoch 114: loss is 0.21210\n",
            "Epoch 115: loss is 0.21062\n",
            "Epoch 116: loss is 0.21033\n",
            "Epoch 117: loss is 0.20993\n",
            "Epoch 118: loss is 0.20770\n",
            "Epoch 119: loss is 0.20732\n",
            "Epoch 120: loss is 0.20495\n",
            "Epoch 121: loss is 0.20542\n",
            "Epoch 122: loss is 0.20396\n",
            "Epoch 123: loss is 0.20298\n",
            "Epoch 124: loss is 0.20143\n",
            "Epoch 125: loss is 0.20008\n",
            "Epoch 126: loss is 0.19882\n",
            "Epoch 127: loss is 0.19876\n",
            "Epoch 128: loss is 0.19762\n",
            "Epoch 129: loss is 0.19634\n",
            "Epoch 130: loss is 0.19386\n",
            "Epoch 131: loss is 0.19356\n",
            "Epoch 132: loss is 0.19270\n",
            "Epoch 133: loss is 0.19082\n",
            "Epoch 134: loss is 0.19138\n",
            "Epoch 135: loss is 0.18959\n",
            "Epoch 136: loss is 0.18888\n",
            "Epoch 137: loss is 0.18730\n",
            "Epoch 138: loss is 0.18731\n",
            "Epoch 139: loss is 0.18390\n",
            "Epoch 140: loss is 0.18406\n",
            "Epoch 141: loss is 0.18412\n",
            "Epoch 142: loss is 0.18358\n",
            "Epoch 143: loss is 0.18173\n",
            "Epoch 144: loss is 0.18100\n",
            "Epoch 145: loss is 0.17754\n",
            "Epoch 146: loss is 0.17889\n",
            "Epoch 147: loss is 0.17794\n",
            "Epoch 148: loss is 0.17584\n",
            "Epoch 149: loss is 0.17535\n",
            "Epoch 150: loss is 0.17512\n",
            "Epoch 151: loss is 0.17441\n",
            "Epoch 152: loss is 0.17170\n",
            "Epoch 153: loss is 0.17172\n",
            "Epoch 154: loss is 0.17137\n",
            "Epoch 155: loss is 0.17036\n",
            "Epoch 156: loss is 0.16683\n",
            "Epoch 157: loss is 0.16767\n",
            "Epoch 158: loss is 0.16918\n",
            "Epoch 159: loss is 0.16555\n",
            "Epoch 160: loss is 0.16549\n",
            "Epoch 161: loss is 0.16484\n",
            "Epoch 162: loss is 0.16204\n",
            "Epoch 163: loss is 0.16128\n",
            "Epoch 164: loss is 0.15987\n",
            "Epoch 165: loss is 0.15929\n",
            "Epoch 166: loss is 0.15896\n",
            "Epoch 167: loss is 0.15838\n",
            "Epoch 168: loss is 0.15676\n",
            "Epoch 169: loss is 0.15524\n",
            "Epoch 170: loss is 0.15555\n",
            "Epoch 171: loss is 0.15515\n",
            "Epoch 172: loss is 0.15348\n",
            "Epoch 173: loss is 0.15259\n",
            "Epoch 174: loss is 0.15354\n",
            "Epoch 175: loss is 0.15219\n",
            "Epoch 176: loss is 0.15227\n",
            "Epoch 177: loss is 0.14954\n",
            "Epoch 178: loss is 0.14733\n",
            "Epoch 179: loss is 0.14758\n",
            "Epoch 180: loss is 0.14734\n",
            "Epoch 181: loss is 0.14580\n",
            "Epoch 182: loss is 0.14545\n",
            "Epoch 183: loss is 0.14441\n",
            "Epoch 184: loss is 0.14376\n",
            "Epoch 185: loss is 0.14274\n",
            "Epoch 186: loss is 0.14312\n",
            "Epoch 187: loss is 0.14178\n",
            "Epoch 188: loss is 0.14144\n",
            "Epoch 189: loss is 0.14127\n",
            "Epoch 190: loss is 0.13819\n",
            "Epoch 191: loss is 0.13765\n",
            "Epoch 192: loss is 0.13875\n",
            "Epoch 193: loss is 0.13570\n",
            "Epoch 194: loss is 0.13548\n",
            "Epoch 195: loss is 0.13524\n",
            "Epoch 196: loss is 0.13369\n",
            "Epoch 197: loss is 0.13447\n",
            "Epoch 198: loss is 0.13282\n",
            "Epoch 199: loss is 0.13476\n",
            "Epoch 200: loss is 0.13414\n",
            "Epoch 201: loss is 0.13071\n",
            "Epoch 202: loss is 0.12848\n",
            "Epoch 203: loss is 0.12828\n",
            "Epoch 204: loss is 0.12491\n",
            "Epoch 205: loss is 0.12555\n",
            "Epoch 206: loss is 0.12601\n",
            "Epoch 207: loss is 0.12647\n",
            "Epoch 208: loss is 0.12568\n",
            "Epoch 209: loss is 0.12409\n",
            "Epoch 210: loss is 0.12397\n",
            "Epoch 211: loss is 0.12274\n",
            "Epoch 212: loss is 0.12079\n",
            "Epoch 213: loss is 0.12106\n",
            "Epoch 214: loss is 0.12172\n",
            "Epoch 215: loss is 0.11918\n",
            "Epoch 216: loss is 0.11788\n",
            "Epoch 217: loss is 0.11787\n",
            "Epoch 218: loss is 0.11854\n",
            "Epoch 219: loss is 0.11656\n",
            "Epoch 220: loss is 0.11508\n",
            "Epoch 221: loss is 0.11728\n",
            "Epoch 222: loss is 0.11406\n",
            "Epoch 223: loss is 0.11542\n",
            "Epoch 224: loss is 0.11443\n",
            "Epoch 225: loss is 0.11164\n",
            "Epoch 226: loss is 0.11057\n",
            "Epoch 227: loss is 0.11127\n",
            "Epoch 228: loss is 0.11088\n",
            "Epoch 229: loss is 0.11100\n",
            "Epoch 230: loss is 0.10897\n",
            "Epoch 231: loss is 0.10858\n",
            "Epoch 232: loss is 0.10721\n",
            "Epoch 233: loss is 0.10947\n",
            "Epoch 234: loss is 0.10649\n",
            "Epoch 235: loss is 0.10675\n",
            "Epoch 236: loss is 0.10605\n",
            "Epoch 237: loss is 0.10723\n",
            "Epoch 238: loss is 0.10467\n",
            "Epoch 239: loss is 0.10282\n",
            "Epoch 240: loss is 0.10297\n",
            "Epoch 241: loss is 0.10367\n",
            "Epoch 242: loss is 0.10211\n",
            "Epoch 243: loss is 0.10252\n",
            "Epoch 244: loss is 0.10069\n",
            "Epoch 245: loss is 0.09907\n",
            "Epoch 246: loss is 0.09809\n",
            "Epoch 247: loss is 0.09991\n",
            "Epoch 248: loss is 0.09852\n",
            "Epoch 249: loss is 0.09702\n",
            "Epoch 250: loss is 0.09987\n",
            "Epoch 251: loss is 0.09682\n",
            "Epoch 252: loss is 0.10008\n",
            "Epoch 253: loss is 0.09881\n",
            "Epoch 254: loss is 0.09510\n",
            "Epoch 255: loss is 0.09471\n",
            "Epoch 256: loss is 0.09356\n",
            "Epoch 257: loss is 0.09253\n",
            "Epoch 258: loss is 0.09598\n",
            "Epoch 259: loss is 0.09599\n",
            "Epoch 260: loss is 0.09225\n",
            "Epoch 261: loss is 0.09378\n",
            "Epoch 262: loss is 0.09499\n",
            "Epoch 263: loss is 0.09105\n",
            "Epoch 264: loss is 0.09144\n",
            "Epoch 265: loss is 0.09026\n",
            "Epoch 266: loss is 0.08823\n",
            "Epoch 267: loss is 0.09513\n",
            "Epoch 268: loss is 0.09035\n",
            "Epoch 269: loss is 0.09026\n",
            "Epoch 270: loss is 0.08708\n",
            "Epoch 271: loss is 0.08853\n",
            "Epoch 272: loss is 0.08596\n",
            "Epoch 273: loss is 0.08450\n",
            "Epoch 274: loss is 0.08733\n",
            "Epoch 275: loss is 0.08715\n",
            "Epoch 276: loss is 0.08726\n",
            "Epoch 277: loss is 0.08274\n",
            "Epoch 278: loss is 0.08576\n",
            "Epoch 279: loss is 0.08548\n",
            "Epoch 280: loss is 0.08150\n",
            "Epoch 281: loss is 0.08588\n",
            "Epoch 282: loss is 0.08227\n",
            "Epoch 283: loss is 0.08139\n",
            "Epoch 284: loss is 0.08264\n",
            "Epoch 285: loss is 0.08264\n",
            "Epoch 286: loss is 0.07992\n",
            "Epoch 287: loss is 0.07855\n",
            "Epoch 288: loss is 0.08274\n",
            "Epoch 289: loss is 0.07802\n",
            "Epoch 290: loss is 0.07697\n",
            "Epoch 291: loss is 0.07761\n",
            "Epoch 292: loss is 0.07784\n",
            "Epoch 293: loss is 0.07739\n",
            "Epoch 294: loss is 0.07650\n",
            "Epoch 295: loss is 0.07659\n",
            "Epoch 296: loss is 0.07578\n",
            "Epoch 297: loss is 0.07513\n",
            "Epoch 298: loss is 0.07553\n",
            "Epoch 299: loss is 0.07431\n",
            "Epoch 300: loss is 0.07380\n",
            "Confusion matrix:\n",
            "[[0.79 0.01 0.03 0.02 0.01 0.   0.14 0.   0.01 0.  ]\n",
            " [0.   0.97 0.   0.02 0.01 0.   0.   0.   0.   0.  ]\n",
            " [0.02 0.01 0.79 0.01 0.1  0.   0.07 0.   0.   0.  ]\n",
            " [0.03 0.02 0.01 0.86 0.03 0.   0.04 0.   0.01 0.  ]\n",
            " [0.   0.   0.1  0.03 0.79 0.   0.07 0.   0.01 0.  ]\n",
            " [0.   0.   0.   0.   0.   0.96 0.   0.02 0.01 0.01]\n",
            " [0.11 0.   0.08 0.02 0.06 0.   0.7  0.   0.01 0.  ]\n",
            " [0.   0.   0.   0.   0.   0.02 0.   0.95 0.   0.03]\n",
            " [0.01 0.   0.   0.   0.   0.   0.02 0.   0.96 0.  ]\n",
            " [0.   0.   0.   0.   0.   0.01 0.   0.04 0.   0.95]]\n",
            "Diagonal values:\n",
            "[0.79 0.97 0.79 0.86 0.79 0.96 0.7  0.95 0.96 0.95]\n",
            "Accuracy: \n",
            "0.8735\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    np.random.seed(2017)\n",
        "    \n",
        "    #numerical check for your layer feedforward and backpropagation\n",
        "    your_layer = Layer((60, 100), 'sigmoid')\n",
        "    unit_test_layer(your_layer)\n",
        "\n",
        "    plt.ion()\n",
        "    mnist_classification()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukKgfwZtRH8y"
      },
      "source": [
        "## 4. Hiện thực neural network bằng tensorflow<a id='C4'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "#import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "tf.enable_eager_execution()\n",
        "tf.keras.backend.clear_session()\n",
        "import matplotlib.pyplot as plt\n",
        "from util import * \n",
        "from dnn_np import test\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enKFoBSRRNQw"
      },
      "source": [
        "#### Tensorflow for Vehicle classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vehicle_classification():\n",
        "    # Load data from file\n",
        "    # Make sure that bat.dat is in data/\n",
        "    train_x, train_y, test_x, test_y = get_vehicle_data()\n",
        "    train_x, test_x = normalize_vehicle(train_x, test_x)    \n",
        "\n",
        "    test_y  = test_y.flatten().astype(np.int32)\n",
        "    train_y = train_y.flatten().astype(np.int32)\n",
        "    num_class = (np.unique(train_y)).shape[0]\n",
        "\n",
        "    train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1]*train_x.shape[2]))\n",
        "    test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1]*test_x.shape[2]))\n",
        " \n",
        "    # DNN parameters\n",
        "    hidden_layers = [100, 100, 100]\n",
        "    learning_rate = 0.01\n",
        "    batch_size = 200\n",
        "    steps = 500\n",
        "   \n",
        "    # Specify that all features have real-value data\n",
        "    feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[train_x.shape[1]])]\n",
        "\n",
        "\n",
        "    # Available activition functions\n",
        "    # https://www.tensorflow.org/versions/r0.12/api_docs/python/nn/activation_functions_\n",
        "    # tf.nn.relu\n",
        "    # tf.nn.elu\n",
        "    # tf.nn.sigmoid\n",
        "    # tf.nn.tanh\n",
        "    activation = tf.nn.relu\n",
        "    \n",
        "    # [TODO 1.7] Create a neural network and train it using estimator\n",
        "\n",
        "    # Some available gradient descent optimization algorithms\n",
        "    # https://www.tensorflow.org/api_guides/python/train#Optimizers\n",
        "    # tf.train.GradientDescentOptimizer\n",
        "    # tf.train.AdadeltaOptimizer\n",
        "    # tf.train.AdagradOptimizer\n",
        "    # tf.train.AdagradDAOptimizer\n",
        "    # tf.train.MomentumOptimizer\n",
        "    # tf.train.AdamOptimizer\n",
        "    # tf.train.FtrlOptimizer\n",
        "    # tf.train.ProximalGradientDescentOptimizer\n",
        "    # tf.train.ProximalAdagradOptimizer\n",
        "    # tf.train.RMSPropOptimizer\n",
        "    # Create optimizer\n",
        "    optimizer = tf.train.ProximalAdagradOptimizer(\n",
        "                                    learning_rate=learning_rate, \n",
        "                                    l2_regularization_strength=0.001)\n",
        "\n",
        "    # optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "    # optimizer = tf.train.MomentumOptimizer(learning_rate=0.01, momentum=0.005)\n",
        "    \n",
        "    # build a deep neural network\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier\n",
        "    classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns, \n",
        "                                    hidden_units= hidden_layers,\n",
        "                                    n_classes=num_class,\n",
        "                                    optimizer= optimizer,\n",
        "                                    activation_fn= activation,\n",
        "                                    model_dir=\"problem1-estimator\")\n",
        "    \n",
        "    # Define the training inputs\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/numpy_input_fn\n",
        "    train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
        "                                    x={\"x\": train_x},\n",
        "                                    y=train_y,\n",
        "                                    num_epochs=None, # None will run forever.\n",
        "                                    batch_size = batch_size,\n",
        "                                    shuffle=True)\n",
        "    \n",
        "    # Train model.\n",
        "    classifier.train(\n",
        "        input_fn=train_input_fn,\n",
        "        steps=steps)\n",
        "    \n",
        "    # Define the test inputs\n",
        "    test_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
        "                                    x={\"x\": test_x},\n",
        "                                    y=test_y,\n",
        "                                    num_epochs=1,\n",
        "                                    shuffle=False)\n",
        "    \n",
        "    # Evaluate accuracy. \n",
        "    predict_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
        "      x={\"x\": test_x},\n",
        "      num_epochs=1,\n",
        "      shuffle=False)\n",
        "\n",
        "    y_hat = classifier.predict(input_fn=predict_input_fn)\n",
        "    y_hat = list(y_hat)\n",
        "    y_hat = np.asarray([int(x['classes'][0]) for x in y_hat]) \n",
        "    test(y_hat, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading vehicle data...\n",
            "EOF Reached\n",
            "Done reading\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'problem1-estimator', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:59: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_7784\\920158858.py:65: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:60: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:914: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into problem1-estimator\\model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 172.03864, step = 1\n",
            "INFO:tensorflow:global_step/sec: 26.6517\n",
            "INFO:tensorflow:loss = 4.1845684, step = 101 (3.755 sec)\n",
            "INFO:tensorflow:global_step/sec: 31.4382\n",
            "INFO:tensorflow:loss = 0.5656804, step = 201 (3.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 31.4076\n",
            "INFO:tensorflow:loss = 0.35462147, step = 301 (3.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 30.8153\n",
            "INFO:tensorflow:loss = 0.19530573, step = 401 (3.244 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 500...\n",
            "INFO:tensorflow:Saving checkpoints for 500 into problem1-estimator\\model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 500...\n",
            "INFO:tensorflow:Loss for final step: 0.09103702.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from problem1-estimator\\model.ckpt-500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Confusion matrix:\n",
            "[[0.8  0.2 ]\n",
            " [0.16 0.84]]\n",
            "Diagonal values:\n",
            "[0.8  0.84]\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    np.random.seed(2017) \n",
        "\n",
        "    plt.ion()\n",
        "    vehicle_classification()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tensorflow for MNIST classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mnist_classification():\n",
        "    # Load data from file\n",
        "    # Make sure that fashion-mnist/*.gz is in data/\n",
        "    train_x, train_y, val_x, val_y, test_x, test_y = get_mnist_data(1)\n",
        "\n",
        "    train_x, val_x, test_x = normalize(train_x, train_x, test_x)    \n",
        "\n",
        "    train_y = train_y.flatten().astype(np.int32)\n",
        "    val_y = val_y.flatten().astype(np.int32)\n",
        "    test_y = test_y.flatten().astype(np.int32)\n",
        "    num_class = (np.unique(train_y)).shape[0]\n",
        "    #pdb.set_trace()\n",
        "\n",
        "    # DNN parameters\n",
        "    hidden_layers = [100, 100, 100]\n",
        "    learning_rate = 0.1\n",
        "    batch_size = 200\n",
        "    steps = 500\n",
        "   \n",
        "    # Specify that all features have real-value data\n",
        "    feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[train_x.shape[1]])]\n",
        "\n",
        "\n",
        "    # Choose activation function\n",
        "    activation = tf.nn.relu\n",
        "    \n",
        "    # Some available gradient descent optimization algorithms \n",
        "    # TODO: [YC1.7] Create optimizer\n",
        "    optimizer = tf.train.ProximalAdagradOptimizer(\n",
        "                                    learning_rate=learning_rate, \n",
        "                                    l2_regularization_strength=0.001)\n",
        "    \n",
        "    # build a deep neural network\n",
        "    classifier = tf.estimator.DNNClassifier(\n",
        "                                    feature_columns=feature_columns,\n",
        "                                    hidden_units= hidden_layers,\n",
        "                                    n_classes=num_class,\n",
        "                                    optimizer= optimizer,\n",
        "                                    activation_fn= activation,\n",
        "                                    model_dir=\"problem2-estimator\") \n",
        "    \n",
        "    # Define the training inputs\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/numpy_input_fn\n",
        "    train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
        "                                    x={\"x\": train_x},\n",
        "                                    y=train_y,\n",
        "                                    num_epochs=None, # None will run forever.\n",
        "                                    batch_size = batch_size,\n",
        "                                    shuffle=True)\n",
        "    \n",
        "    # Train model.\n",
        "    classifier.train(\n",
        "        input_fn=train_input_fn,\n",
        "        steps=steps)\n",
        "    \n",
        "    # Define the test inputs\n",
        "    test_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
        "                                    x={\"x\": test_x},\n",
        "                                    y=test_y,\n",
        "                                    num_epochs=1,\n",
        "                                    shuffle=False)\n",
        "    \n",
        "    # Evaluate accuracy. \n",
        "    predict_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
        "      x={\"x\": test_x},\n",
        "      num_epochs=1,\n",
        "      shuffle=False)\n",
        "    y_hat = classifier.predict(input_fn=predict_input_fn)\n",
        "    y_hat = list(y_hat)\n",
        "    y_hat = np.asarray([int(x['classes'][0]) for x in y_hat]) \n",
        "    test(y_hat, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading fashion MNIST data...\n",
            "Done reading\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'problem2-estimator', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from problem2-estimator\\model.ckpt-500\n",
            "WARNING:tensorflow:From c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1173: get_checkpoint_mtimes (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 500...\n",
            "INFO:tensorflow:Saving checkpoints for 500 into problem2-estimator\\model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 500...\n",
            "INFO:tensorflow:loss = 98.37024, step = 501\n",
            "INFO:tensorflow:global_step/sec: 154.946\n",
            "INFO:tensorflow:loss = 68.872505, step = 601 (0.647 sec)\n",
            "INFO:tensorflow:global_step/sec: 121.156\n",
            "INFO:tensorflow:loss = 70.12506, step = 701 (0.825 sec)\n",
            "INFO:tensorflow:global_step/sec: 124.002\n",
            "INFO:tensorflow:loss = 52.362, step = 801 (0.805 sec)\n",
            "INFO:tensorflow:global_step/sec: 157.676\n",
            "INFO:tensorflow:loss = 73.67313, step = 901 (0.634 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000...\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into problem2-estimator\\model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000...\n",
            "INFO:tensorflow:Loss for final step: 75.159225.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from problem2-estimator\\model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Confusion matrix:\n",
            "[[0.82 0.   0.01 0.06 0.   0.   0.09 0.   0.01 0.  ]\n",
            " [0.   0.96 0.   0.03 0.   0.   0.   0.   0.   0.  ]\n",
            " [0.02 0.   0.76 0.01 0.1  0.   0.11 0.   0.01 0.  ]\n",
            " [0.03 0.01 0.01 0.88 0.03 0.   0.03 0.   0.   0.  ]\n",
            " [0.   0.   0.12 0.04 0.76 0.   0.08 0.   0.01 0.  ]\n",
            " [0.   0.   0.   0.   0.   0.94 0.   0.03 0.   0.02]\n",
            " [0.16 0.   0.07 0.05 0.08 0.   0.62 0.   0.02 0.  ]\n",
            " [0.   0.   0.   0.   0.   0.03 0.   0.94 0.   0.03]\n",
            " [0.01 0.   0.   0.01 0.   0.   0.01 0.   0.96 0.  ]\n",
            " [0.   0.   0.   0.   0.   0.01 0.   0.04 0.   0.95]]\n",
            "Diagonal values:\n",
            "[0.82 0.96 0.76 0.88 0.76 0.94 0.62 0.94 0.96 0.95]\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    np.random.seed(2017) \n",
        "\n",
        "    plt.ion()\n",
        "    mnist_classification()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5 Kết quả <a id='C5'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlidH1M6jjOe"
      },
      "source": [
        "### 5.1. Vehicle Classification <a id='*C5_1*'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Numpy:\n",
        "- Epoch 500: loss is 0.09120\n",
        "- Confusion matrix:\n",
        "$$\\begin{bmatrix} 0.82 & 0.18 \\\\ 0.17 & 0.83 \\end{bmatrix}$$\n",
        "- Diagonal values:\n",
        " $$\\begin{bmatrix} 0.82 & 0.83 \\end{bmatrix}$$\n",
        "- Accuracy: \n",
        "0.8216666666666667\n",
        "\n",
        "#### Tensorflow:\n",
        "- INFO:tensorflow:Loss for final step: 0.09103702.\n",
        "- Confusion matrix:\n",
        "$$\\begin{bmatrix} 0.8 & 0.2 \\\\ 0.16 & 0.84 \\end{bmatrix}$$\n",
        "- Diagonal values:\n",
        "$$\\begin{bmatrix} 0.8 & 0.84 \\end{bmatrix}$$\n",
        "- Accuracy: 0.82\n",
        "\n",
        "Kết quả khi sử dụng numpy có vẻ ổn định và chính xác hơn khi sử dụng Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2. MNIST Classification <a id='*C5_2*'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Numpy:\n",
        "- Epoch 300: loss is 0.07380\n",
        "- Confusion matrix:\n",
        "$$\\begin{bmatrix} 0.79 & 0.01 & 0.03 & 0.02 & 0.01 & 0. & 0.14 & 0. & 0.01 & 0. \n",
        "    \\\\ 0. & 0.97 & 0. & 0.02 & 0.01 & 0. & 0. & 0. & 0. & 0.\n",
        "    \\\\ 0.02 & 0.01 & 0.79 & 0.01 & 0.1 & 0. & 0.07 0. & 0. & 0.\n",
        "    \\\\ 0.03 & 0.02 & 0.01 & 0.86 & 0.03 & 0. & 0.04 & 0. & 0.01 & 0.\n",
        "    \\\\ 0. & 0. & 0.1 & 0.03 & 0.79 & 0. & 0.07 & 0. & 0.01 & 0.\n",
        "    \\\\ 0. & 0. & 0. & 0. & 0. & 0.96 & 0. & 0.02 & 0.01 & 0.01\n",
        "    \\\\ 0.11 & 0. & 0.08 & 0.02 & 0.06 & 0. & 0.7 & 0. & 0.01 & 0.\n",
        "    \\\\ 0. & 0. & 0. & 0. & 0. & 0.02 & 0. & 0.95 & 0. & 0.03\n",
        "    \\\\ 0.01 & 0. & 0. & 0. & 0. & 0. & 0.02 & 0. & 0.96 & 0.\n",
        "    \\\\ 0. & 0. & 0. & 0. & 0. & 0.01 & 0. & 0.04 & 0. & 0.95\n",
        "    \\end{bmatrix}$$\n",
        "- Diagonal values:\n",
        "$$\\begin{bmatrix} 0.79 & 0.97 & 0.79 & 0.86 & 0.79 & 0.96 & 0.7 & 0.95 & 0.96 & 0.95 \\end{bmatrix}$$\n",
        "- Accuracy: \n",
        "0.8735\n",
        "#### Tensorflow:\n",
        "- INFO:tensorflow:Loss for final step: 66.0305.\n",
        "- Confusion matrix:\n",
        " $$\\begin{bmatrix} 0.77 & 0. & 0.02 & 0.08 & 0. & 0. & 0.12 & 0. & 0.01 & 0. \n",
        "    \\\\ 0. & 0.96 & 0. & 0.03 & 0.01 & 0. & 0. & 0. & 0. & 0.\n",
        "    \\\\ 0.01 & 0. & 0.82 & 0.02 & 0.1 & 0. & 0.05 & 0. & 0.01 & 0.\n",
        "    \\\\ 0.01 & 0.01 & 0.01 & 0.9 & 0.04 & 0. & 0.02 & 0. & 0.01 & 0.\n",
        "    \\\\ 0. & 0. & 0.15 & 0.04 & 0.76 & 0. & 0.04 & 0. & 0. & 0.\n",
        "    \\\\ 0. & 0. & 0. & 0. & 0. & 0.93 & 0. & 0.04 & 0.01 & 0.02\n",
        "    \\\\ 0.12 & 0. & 0.13 & 0.06 & 0.08 & 0. & 0.59 & 0. & 0.01 & 0.\n",
        "    \\\\ 0. & 0. & 0. & 0. & 0. & 0.02 & 0. & 0.96 & 0. & 0.02\n",
        "    \\\\ 0. & 0. & 0. & 0.01 & 0.01 & 0. & 0.01 & 0. & 0.97 & 0.\n",
        "    \\\\ 0. & 0. & 0. & 0. & 0. & 0. & 0. & 0.06 & 0. & 0.94\n",
        "    \\end{bmatrix}$$\n",
        "- Diagonal values:\n",
        "$$\\begin{bmatrix} 0.77 & 0.96 & 0.82 & 0.9 & 0.76 & 0.93 & 0.59 & 0.96 & 0.97 & 0.94 \\end{bmatrix}$$\n",
        "- Accuracy: 0.86\n",
        "\n",
        "Kết quả khi sử dụng numpy có vẻ ổn định và chính xác hơn khi sử dụng Tensorflow"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "MSU-sZg3oM7N",
        "GwSNZlg2qFCv",
        "enKFoBSRRNQw",
        "WkG26LWSSdDg",
        "69rProsfTYWS",
        "Yy_5nMf7mOTW"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "31671a60cee805c34c73116577b485118ff3a75c458d3004d49632c19702ac60"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
